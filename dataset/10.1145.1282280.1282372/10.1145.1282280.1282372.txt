FXPAL MediaMagic  Video Search System 
John Adcock 
FX Palo Alto Laboratory Inc  
3400 Hillview Ave, Bldg 4  
Palo Alto, CA 94304  
+1 650 813 7374 
adcock@fxpal.com Matthew Cooper 
FX Palo Alto Laboratory Inc 
3400 Hillview Ave, Bldg 4 
Palo Alto, CA 94304 
+1 650 813 7145 
cooper@fxpal.com Francine Chen 
FX Palo Alto Laboratory Inc  
3400 Hillview Ave, Bldg 4  
 Palo Alto, CA 94304 
+1 650 813 7327 
chen@fxpal.com 
 
ABSTRACT  
This paper describes FXPAL’s interactive video sear ch 
application, “MediaMagic” [1].  
Categories and Subject Descriptors  
H.5.1. Information interfaces and presentation: Mul timedia 
information systems – video.  
General Terms  
Algorithms, Design, Experimentation, Human Factors.  
Keywords  
TRECVID, video search, interactive 
1.  INTRODUCTION 
FXPAL has participated in the TRECVID [2] interacti ve search 
task since 2004. In our search application we emplo y a rich set of 
redundant visual cues to help the searcher quickly sift through the 
video collection. A central element of the interfac e and underlying 
search engine is a segmentation of the video into s tories, which 
allows the user to quickly navigate and evaluate th e relevance of 
moderately-sized, semantically-related chunks. 
2.  MULTILEVEL INDEXING 
Videos and query results are handled at 3 levels of  granularity in 
our system. In order from longest to shortest they are: program, 
story, and shot. In a wide variety of video genres,  including news 
and documentaries, shots with wildly varying visual  content may 
be contained within a single, semantically coherent , story.  We 
combine latent semantic analysis [3] of the text tr anscripts and a 
similarity-based segmentation technique [4] with th e video-based 
shot boundaries to automatically create a story-lev el 
segmentation. 
3.  RICH PRESENTATION 
Figure 1 shows the search interface. Stories are th e main units for 
presenting query results to the user and are summar ized and sized 
according to their retrieval scores on the left. Th e visual 
indication of query relevance is repeated in the co loring of the 
video timeline and individual shot thumbnails on th e right side. 
Shots and stories garner a gray (visited), green (r elevant), or red 
(non-relevant) overlay as they are visited so that the searcher can 
avoid retracing the same path. In addition to the e xtensive use of visual cues, the interface extensively employs drag -and-drop for 
convenience and hot keys for power searchers. 
4.  SEARCH ENGINE 
Initial queries are specified in the form of keywor ds and example 
images. The searcher-entered text is used for fuzzy  text search 
within a latent semantic space that takes advantage  of the 
automatic story segmentation of the corpus. In addi tion, any 
selection of stories or shots can be used as the ba sis of a new “ find 
similar ” query based upon the textual, visual, and concept ual 
content of the selection. In this way the searcher can explore a 
region of the corpus without explicitly forming a q uery that 
defines it. 
5.  REFERENCES 
[1]  J. Adcock, M. Cooper, A. Girgensohn, L. Wilcox.  Interactive 
Video Search Using Multilevel Indexing. CIVR 2005, 205-
214 
[2]  TRECVID: TREC video retrieval evaluation Workshop 
(2001-2006). http://www-nlpir.nist.gov/projects/tre cvid/ 
[3]  Berry, M.W., Dumais, S.T., O’Brien, G.W. Using line ar 
algebra for intelligent information retrieval. SIAM  Rev. 37 
(1995) 573–595 
[4]  Cooper, M., Foote, J. Scene boundary detection via video 
self-similarity analysis. In: IEEE Intl. Conf. on I mage 
Processing. (2001) 378–381  
 
Copyright is held by the author/owner(s). 
CIVR'07 , July 9-11, 2007, Amsterdam, The Netherlands. 
Copyright 2007 ACM 978-1-59593-733-9/07/0007.  
 
Figure 1: MediaMagic  interface. Retrieved stories on the left 
are expanded in the player and shot viewer on the r ight. 
The TRECVID query and example media are at the bott om. 
644