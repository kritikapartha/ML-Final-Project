Image Search 2.0
Xi
rong Li
Intelligent Systems Lab Amsterdam, Informatics Institute, University of Amsterdam
Science Park 904, 1098XH Amsterdam, The Netherlands
x.li@uva.nl
ABSTRACT
This abstract sketches my PhD research towards establish-
ing a generic mechanism for exploiting social intelligence for
next-generation image search.
Categories and Subject Descriptors: H.3.3Information
Storage and Retrieval: Information Search and Retrieval
General Terms: Algorithms,Experimentation,Performance
Keywords: Image search, big social data
1. PROBLEM STATEMENT
Imagesearchiscrucialforuserswithvaryingsortsofinfor-
mation needs. Applications of image search include person-
alized information delivery, cultural heritage preservation,
knowledge representation, and forensic intelligence, to name
just a few. The problem is scientiﬁcally challenging due to
the famous semantic gap problem.
Traditionally, research on image search focuses on ingre-
dients ranging from robust representation of visual content,
semantic-sensitive visual rankers, to user-friendly visualiza-
tionofsearchresults. Inthistradition, whichweterm Image
Search 1.0 , the image data itself is seldom recognized as the
source of innovation. However, the world has started to col-
lect massive amounts of user-generated data online. Social
image tagging is making a profound impact on the way peo-
ple manage and access visual content. We hypothesize the
proliferation of social data will reshape research on image
retrieval. After all, it is not just a matter of big data. In-
tellectual approaches are essential to conquer the ambiguity,
unreliability, and sparseness of social tagging, and to aggre-
gate the immense miscellaneous information scattered in the
social web.
The main goal of my PhD research is to study the value of
big data on the social web, to gain insight into their visual
nature, and to obtain universal knowledge from the data for
semantic understanding of visual content, for free. We term
thisImage Search 2.0 .
2. APPROACHES AND PROGRESS
Given the subjective nature of social tagging, interpreting
the relevance of a social tag with respect to the visual con-
tent is crucial for the eﬀective exploration of social data. We
propose a neighbor voting algorithm which accurately and
eﬃciently learns tag relevance by accumulating votes from
Copyright is held by the author/owner(s).
MM’11, November 28–December 1, 2011, Scottsdale, Arizona, USA.
ACM 978-1-4503-0616-4/11/11.visual neighbors [3,5]. In our best paper awarded work [6],
we extend the algorithm to fuse multiple tag relevance esti-
mates driven by diverse features. We clean up social data
by tag relevance learning, and leverage them for tagging un-
labeled images [4].
To bridge the semantic gap for retrieving unlabeled im-
ages, we need both positive examples and negative examples
for obtaining visual classiﬁers. Along with our tag relevance
learning approach to harvesting positive examples [5,6], we
study how to harvest negative examples from the social
web [2,8]. We show the potential of data-mining informa-
tive negative examples without the need of extra manual
annotation [8].
Grounded on the above work, we initiate an image search
engine which searches for the co-occurrence of multiple vi-
sual concepts in unlabeled images, fully driven by social
data [7]. We study personalizing image annotation with re-
spect to a user’s multimedia tagging history [1]. We consider
these two pieces of work as important steps towards answer-
ing complex queries for personalized image search.
In sum, this research aims to reveal the value of social
multimedia, providing a generic mechanism to exploit social
intelligence for image search.
Acknowledgements . This research was sponsored by
theEC-FP6VIDI-VideoandtheSTWSEARCHERprojects.
3. REFERENCES
[1] X. Li, E. Gavves, C. Snoek, M. Worring, and
A. Smeulders. Personalizing automated image
annotation using cross-entropy. In ACM MM, 2011.
[2] X. Li and C. Snoek. Visual categorization with negative
examples for free. In ACM MM, 2009.
[3] X. Li, C. Snoek, and M. Worring. Learning tag
relevance by neighbor voting for social image retrieval.
InMIR, 2008.
[4] X. Li, C. Snoek, and M. Worring. Annotating images
by harnessing worldwide user-tagged photos. In
ICASSP, 2009.
[5] X. Li, C. Snoek, and M. Worring. Learning social tag
relevance by neighbor voting. IEEE Trans. MM,
11(7):1310–1322, 2009.
[6] X. Li, C. Snoek, and M. Worring. Unsupervised
multi-feature tag relevance learning for social image
retrieval. In CIVR, 2010.
[7] X. Li, C. Snoek, M. Worring, and A. Smeulders.
Harvesting social images for bi-concept search. IEEE
Trans. MM. submitted.
[8] X. Li, C. Snoek, M. Worring, and A. Smeulders. Social
negative bootstrapping for visual categorization. In
ICMR, 2011.
887