{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "import json\n",
    "from rake_nltk import Rake\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all terms from index_terms.json\n",
    "#  note. this gets all leaves in the json i.e. lowest level terms\n",
    "term_tree = json.load(open(\"index_terms.json\"))\n",
    "\n",
    "def get_leafs(term_tree):\n",
    "    terms = set()\n",
    "    queue = [term_tree]\n",
    "\n",
    "    while(queue):\n",
    "        curr_dict = queue.pop()\n",
    "        for key in curr_dict:\n",
    "            if(curr_dict[key]):\n",
    "                queue.append(curr_dict[key])\n",
    "            else:\n",
    "                terms.add(key.lower())\n",
    "    return terms\n",
    "\n",
    "terms = get_leafs(term_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicRank(text):\n",
    "\n",
    "# load a spaCy model, depending on language, scale, etc.\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # add PyTextRank to the spaCy pipeline\n",
    "    nlp.add_pipe(\"topicrank\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tr = doc._.textrank\n",
    "        \n",
    "    topics = set()\n",
    "\n",
    "    for node in tr.node_list:\n",
    "        for topic in node:\n",
    "            topics.add(str(topic).lower())\n",
    "            \n",
    "    return topics\n",
    "\n",
    "def rake(text):\n",
    "    # print(text)\n",
    "    r = Rake(min_length=1, max_length=8, include_repeated_phrases=False)\n",
    "    r.extract_keywords_from_text(text)\n",
    "    ranked_keywords = r.get_ranked_phrases()\n",
    "    top_keywords = ranked_keywords[:5000]\n",
    "    \n",
    "    keywords = set()\n",
    "    for keyword in top_keywords:\n",
    "        keywords.add(str(keyword).lower())\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text\n",
    "# text = \"Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types.\"\n",
    "doi = \"10.1145.3351095.3372826\"\n",
    "text = open(f\"dataset/{doi}/{doi}.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krish\\OneDrive\\Documents\\ML-Final-Project\\TopicRank.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m topics \u001b[39m=\u001b[39m topicRank(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(topics\u001b[39m.\u001b[39mintersection(terms))\n",
      "\u001b[1;32mc:\\Users\\krish\\OneDrive\\Documents\\ML-Final-Project\\TopicRank.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# add PyTextRank to the spaCy pipeline\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m nlp\u001b[39m.\u001b[39madd_pipe(\u001b[39m\"\u001b[39m\u001b[39mtopicrank\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m tr \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39mtextrank\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m topics \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\language.py:1037\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m   1017\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1018\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1021\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1022\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[0;32m   1023\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1037\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text)\n\u001b[0;32m   1038\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1039\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\language.py:1128\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[39mreturn\u001b[39;00m doc_like\n\u001b[0;32m   1127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_doc(doc_like)\n\u001b[0;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1130\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\language.py:1120\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length:\n\u001b[0;32m   1117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1118\u001b[0m         Errors\u001b[39m.\u001b[39mE088\u001b[39m.\u001b[39mformat(length\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(text), max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length)\n\u001b[0;32m   1119\u001b[0m     )\n\u001b[1;32m-> 1120\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(text)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\tokenizer.pyx:151\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\tokenizer.pyx:187\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize_affixes\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\tokenizer.pyx:391\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\tokenizer.pyx:470\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._attach_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\vocab.pyx:165\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.get\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\vocab.pyx:202\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spacy\\lang\\lex_attrs.py:145\u001b[0m, in \u001b[0;36mlower\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlower\u001b[39m(string: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mreturn\u001b[39;00m string\u001b[39m.\u001b[39mlower()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "topics = topicRank(text)\n",
    "\n",
    "print(topics.intersection(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pointing', 'metrics', 'sociology', 'trees', 'law', 'social networks', 'abstraction', 'copyrights', 'design', 'frameworks', 'taxation', 'bioinformatics', 'women', 'men', 'measurement', 'patterns', 'medical records'}\n",
      "\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 1024: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krish\\OneDrive\\Documents\\ML-Final-Project\\TopicRank.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(text_path)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(text_path)\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m terms_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_dir, doi, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdoi\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(terms_path)):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mcharmap_decode(\u001b[39minput\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 1024: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"./dataset\"\n",
    "for doi in os.listdir(dataset_dir):\n",
    "    text_path = os.path.join(dataset_dir, doi, f\"{doi}.txt\")\n",
    "    if(not os.path.exists(text_path)):\n",
    "        continue\n",
    "    print()\n",
    "    text = open(text_path).read()\n",
    "    \n",
    "    terms_path = os.path.join(dataset_dir, doi, f\"{doi}.json\")\n",
    "    if(not os.path.exists(terms_path)):\n",
    "        continue\n",
    "    \n",
    "    gt_term_tree = json.load(open(terms_path))\n",
    "    gt_terms = get_leafs(gt_term_tree)\n",
    "    \n",
    "    topicRank_topics = topicRank(text)\n",
    "    topicRank_terms = topicRank_topics.intserection(terms)\n",
    "    \n",
    "    \n",
    "    rake_topics = rake(text)\n",
    "    rake_terms = rake_topics.intersection(terms)\n",
    "    \n",
    "    print(rake_terms)\n",
    "    print(gt_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krish\\OneDrive\\Documents\\ML-Final-Project\\TopicRank.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Documents/ML-Final-Project/TopicRank.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m json\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mdataset/10.1145.3351095.3372826/10.1145.3351095.3372826.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39;49mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, object_hook\u001b[39m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39mparse_float, parse_int\u001b[39m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39mparse_constant, object_pairs_hook\u001b[39m=\u001b[39mobject_pairs_hook, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "json.load(\"dataset/10.1145.3351095.3372826/10.1145.3351095.3372826.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
