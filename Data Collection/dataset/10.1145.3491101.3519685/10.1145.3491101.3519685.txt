Collecting and Reporting Race and Ethnicity Data in HCI
Yiqun T. Chen
University of Washington, Seattle
Seattle, WA, United States
yiqunc@uw.eduAngela D. R. Smith
University of Texas at Austin
Austin, TX, United States
adrsmith@utexas.edu
Katharina Reinecke
University of Washington, Seattle
Seattle, WA, United States
reinecke@cs.washington.eduAlexandra To
Northeastern University
Boston, MA, United States
a.to@northeastern.edu
ABSTRACT
Engaging racially and ethnically diverse participants in Human-
Computer Interaction (HCI) research is critical for creating safe,
inclusive, and equitable technology. However, it remains unclear
why and how HCI researchers collect study participants’ race and
ethnicity. Through a systematic literature analysis of 2016–2021
CHI proceedings and a survey with 15 authors who published in
these proceedings, we found that reporting race and ethnicity of
participants is uncommon and that HCI researchers are far from
consensus on the collection and analysis of this data. Because a
majority (>90%) of the articles that report participants’ race and
ethnicity are conducted in the United States, we focused our dis-
cussion on race and ethnicity accordingly. In future work, we plan
to investigate considerations and best practices for collecting and
analyzing race and ethnicity data in a global context.
CCS CONCEPTS
•Human-centered computing →Empirical studies in HCI ;•
Social and professional topics →Race and ethnicity .
KEYWORDS
race, ethnicity, systematic literature review, HCI research, survey
ACM Reference Format:
Yiqun T. Chen, Angela D. R. Smith, Katharina Reinecke, and Alexandra To.
2022. Collecting and Reporting Race and Ethnicity Data in HCI . In CHI
Conference on Human Factors in Computing Systems Extended Abstracts (CHI
’22 Extended Abstracts), April 29-May 5, 2022, New Orleans, LA, USA. ACM,
New York, NY, USA, 8 pages. https://doi.org/10.1145/3491101.3519685
1 INTRODUCTION
As identities of study participants have proven to influence the up-
take, experience, and benefits of technologies, the Human-Computer
Interaction (HCI) community has made considerable efforts to-
wards inclusive and diverse research practices over the past few
years [ 1,7,11,16,42,43,47]. For instance, gender HCI has emerged
as a mature subfield of HCI that focuses on variations in how people
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA
©2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9156-6/22/04.
https://doi.org/10.1145/3491101.3519685of different genders interact with technology [ 46]. As another exam-
ple, HCI for development is a growing subfield that considers how
designs and technologies interact with the under-resourced and
economically disadvantaged communities [ 48,51]. In this work, we
focus on one such diversity dimension — race and ethnicity of par-
ticipants in HCI — which has remained relatively under-explored
in current research. In 2017, Schlesinger et al . [42] found that less
than 0.1% of the papers in the CHI proceedings between 1981 and
2016 engaged meaningfully with race, compared to 0.2% and 0.6%
for gender and socioeconomic class, respectively. Similar findings
were reported on the basis of a quantitative content analysis of
accepted papers in CHI 2006, 2011, and 2016 [ 16]. The authors
highlighted the importance of intersectionality (i.e., an identity
framework that seeks to understand the complexity of multiple,
overlapping, intersecting social identities [ 8,39]) when examining
the composition of the participants in HCI research. In particular,
they emphasized that HCI researchers should take an interest in
understanding how various dimensions of participants’ identities
(e.g., race, gender, socioeconomic status) interact with each other,
and provide recommendations for deeper engagements with the
resulting complex identities.
Other research has explored the issue of race, ethnicity, and bias
in HCI research and the HCI community via a critical race theory
lens [ 33,44]. Ogbonnaya-Ogburu et al . [33] argued that racism is
pervasive in social-technical systems and implored that HCI re-
search should be attuned to the issue of race; they suggested that
participation of under-represented minorities must be sought after
inallresearch activities. Concerted efforts among HCI researchers
also led to a workshop titled “engaging in race in HCI” in CHI
2020 that aimed to identify better practices for engaging with race
and improving racial inclusiveness and equity in HCI [ 44]. This
workshop allowed the HCI community to begin assembling rec-
ommendations for like-minded researchers to discuss the role and
implication of race in HCI, which ultimately led to a series of zines
featuring race and inclusiveness in HCI research [37].
Of course, the topic of collecting and reporting race is not unique
to HCI. For instance, in medical sciences, the American Medical
Association (AMA) Manual of Style states that “specifying the race
or ethnicity of study participants can provide information about the
generalizability of the results of a specific study ”; therefore, it recom-
mends reporting aggregate race and ethnicity for allstudy partici-
pants [ 12]. The American Psychological Association (APA) [ 2] has
made similar suggestions for empirical studies in psychology. How-
ever, given the breadth of research interests and methodologies ofCHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA Chen et al.
HCI, we should neither copy nor ignore existing recommendations
from other disciplines.
When put together, the existing work calls for a deeper under-
standing of the current practice on reporting race in HCI research.
Therefore, our work makes strides towards this goal by answering
the following research questions:
RQ1: Who are the study participants in HCI and when are their
race and ethnicity information reported?
RQ2: What are some considerations that speak for and against
collecting this information?
By answering the two research questions (primarily in the con-
text of race and ethnicity in the United States (U.S.)), we make the
following contributions to the literature:
•We provide an empirical analysis of the frequency of re-
porting CHI participants’ race and ethnicity, showing that
less than 3% of CHI papers in the past six proceedings have
included such information.
•Through a survey with selected authors who published in
CHI, we summarize the motivations for and against reporting
race and ethnicity in HCI research.
2 RELATED WORK
Our work is motivated by both the practice of racial data collection
outside of HCI and the growing efforts to improve the collection of
related demographic variables such as gender [ 32,41,45] within
HCI. In this section, we first briefly review the racial categoriza-
tion in the U.S., which provides the foundation for our quantitative
analysis. Furthermore, we provide a selective overview of the prac-
tices for collecting and analyzing racial data in several research
disciplines. We end the section by sketching how those approaches
might inspire parallel efforts towards racial data in HCI.
2.1 Racial categorization in the U.S.
Racial categories have been included on every U.S. census since 1790,
and the history of U.S. census reveals the complexity of racial and
ethnic data collection [ 36]. Firstly, prior to the 1960 census, an indi-
vidual’s race was determined by census enumerators, rather than
through self-report. Moreover, categories used in census changed
almost every decade to reflect the politics and societal values at the
time. For instance, “Native Hawaiian or Other Pacific Islander” was
historically grouped with Asians, and only became a new category
since 2000. “Mexicans” were counted as a racial category in 1930,
but as that category has since disappeared, many resort to the “other
race” option and have been grouped under the Hispanics ethnicity
only. The ability to identify as multi-racial was only won through
extensive advocacy in 2000 [ 53]. Racial categorization has always
been extremely political, and the miscategorization and undercount
of people from racial minority groups has contributed to systemic
oppression and exclusions [4].
U.S.-based researchers may be familiar with the standards pub-
lished by the U.S. Office of Management and Budget (OMB) in 1997,
which mandates minimum standards for collecting and present-
ing data on race and ethnicity for all federal purposes. The OMB
standards have two categories for ethnicity (Hispanic versus non-
Hispanic) and five categories for racial data at minimum — White,
Black or African American, American Indian or Alaska Native,Asian, and Native Hawaiian or Other Pacific Islander. The OMB
standards have been the guideline for collecting and presenting
data on race and ethnicity for all federal reporting , including the
decennial census and the mandates by U.S. grant funding agencies
such as the National Institutes of Health (NIH) and the National
Science Foundation (NSF) [30, 31].
2.2 Collection and analysis of racial data in
research
Here, we look at how social, medical, and computer sciences have
approached racial data as comparative case studies.
Social science scholars have long acknowledged the role of race
in shaping individuals’ social status and everyday life experience [ 5,
14,14,25]. However, there is less consensus on whether the field
should use racial classifications to assess the role and consequences
of race. Some argue that collecting and reporting data on race and
ethnicity would promote racial division and further the status quo of
racial discrimination, while others take a “what we cannot measure,
we cannot understand” approach, and continue to report observed
racial differences from profiling in law enforcement to disparity in
healthcare systems. In 2003, the American Sociological Association
(ASA) issued a statement in support of continual collection and
research of data on race [ 3]. Their reasoning is summarized as
follows: (i) racial identities are central to societal organization and
relationships, and therefore the very core of social science research;
(ii) taking a “color-blind" approach and ignoring participants’ race
in research does not eliminate the use of racial categories and racism
in everyday life and, consequently, the impact on societal outcomes;
and (iii) understanding the role of race is central to challenging the
existing systems of racial discrimination and stratification.
In contrast to the debates over racial data collection in social sci-
ences, race and ethnicity of study participants are widely collected
and used in healthcare databases to ascertain important group-level
differences in healthcare outcomes in the U.S. [ 22,34]. Despite this
established practice, the basis of the observed race-associated differ-
ences in healthcare outcomes remains under-explored. Jones [19]
argued that as a social construct, race only serves as a very rough
proxy for variables of interest such as social class and culture. In-
stead, race appears predictive of healthcare outcomes because of the
racism that has operated throughout the U.S. history and to date. As
an example, an analysis by Jones et al . [20] demonstrated that being
classified by others as “White” is associated with better health status,
regardless of one’s self-identification . In view of the complex inter-
pretation of “race”, multiple threads of work have urged researchers
in public health to take an interest in elucidating the underlying
causes of the observed differences across race and ethnicity groups,
e.g., by generating hypotheses about the basis and designing data
collection and analysis plans to test the hypotheses. For instance,
the difference in rates of estrogen-receptor-negative breast cancer
between Black and White women in the U.S. is well-documented.
Building on this observation, Krieger et al . [24] demonstrated that
being born in the states that practiced Jim Crow laws (i.e., legal
racial segregation) is associated with higher odds of cancer, thereby
attributing the observed differences to racially discriminating laws.
Within HCI, several authors have argued, through qualitative,
mixed-methods, or quantitative methods, that there is a generalCollecting and Reporting Race and Ethnicity Data in HCI CHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA
lack of meaningful engagement with race and ethnicity [ 16,33,
37,42]. However, the current practice, as well as the motivations,
for collecting and reporting study participants’ race and ethnicity
remains under-explored. In this work, we analyzed recent CHI
proceedings to understand the existing practice. Furthermore, we
also surveyed authors to identify the motivations and methods for
collecting racial and ethnic data of their participants. In future work,
we hope to curate a list of considerations and “best practices” on
collecting race and ethnicity data (similar to those on the gender of
study participants [32, 41, 45]) for HCI researchers.
3 METHOD
To answer our research questions, we conducted a systematic liter-
ature analysis of the published papers in the most recent six CHI
proceedings from 2016 to 2021 and followed up with a survey to
the authors whose papers reported race and ethnicity data of their
participants in this time period. The restriction on time is motivated
by (i) the goal to understand the current practice on collecting racial
and ethnic data of study participants, and (ii) the observation that
older literature rarely reports this information [16].
3.1 Dataset curation
We started with a total of 3,910 research articles published in the
most recent six proceedings of CHI on ACM digital library and pro-
ceeded with a keyword-search method informed by prior work [ 16,
42]. We initially filtered the collection using the keywords “race”
OR “racial” OR “ethnicity”, which narrowed down the corpus to 663
articles. We then experimented with adding potentially defining
keywords (race/racial, ethnicity/ethnic, White/Caucasian, African
American/Black, Asian, Hispanic, Native American/American In-
dian, Pacific Islanders), and sampled the first 10 articles returned
in each year to judge the quality of our search (the quality here is
defined to be the number of search results that contained detailed
race and ethnicity information of the study participants). The final
keyword set that yielded most relevant articles empirically is (i)
“race” OR “racial” OR “ethnicity” AND (ii) “Hispanic” OR “African
American” OR “Asian” OR “Caucasian”. After identifying this initial
collection of 340 articles, we then checked for the racial and ethnic
composition of study participants in each article manually. Next,
we aggregated the racial and ethnic information of study partici-
pants over all articles that detailed this information. Because of the
focus on the race and ethnicity in the U.S. context for this work,
we further limit the corpus to those articles whose authors had
U.S. affiliations orwhose participants were recruited in the U.S. We
display the corpus curation process in Figure 3 of the Appendix.
For reference, we obtained racial and ethnic composition from
two additional sources: (i) the 2015–2019 demographics estimates
of the U.S. collected by the United States Census Bureau [ 49]; and
(ii) the 2015–2019 demographics estimates of U.S.-based drug trials
collected by the U.S. Food and Drug Administration (FDA) [6].
3.2 Dataset analysis
As stated in Section 2.1, categorization of race and ethnicity is ex-
tremely complex. In this paper, as a proof of concept, we adopted
the following procedures to group the race and ethnicity categoriesacross different studies. Firstly, we made the simplifying assump-
tion that the racial categories reported by studies in our final corpus
refers to the non-Hispanic subset (e.g., reported White participants
are non-Hispanic Whites). This is because all studies in the final
corpus are U.S.-based, and many collected race and ethnicity using
one single question. As a result, data was reported for a separate
“Hispanic” group, regardless of participants’ racial identification.
Secondly, we aggregated the participants into the following cate-
gories that roughly align with the OMB standards: White, Black or
African American, Asian, and Others (including American Indian
and Alaska Native, Mixed races, Native Hawaiian and Other Pa-
cific Islander). This choice of analysis is largely driven by reported
racial categories in papers published in CHI, which certainly does
not capture the full complexity of race and ethnicity of the study
participants, even in the context of the U.S.
In addition to the aggregate analysis of studies, we also report
the following statistics of interest: (i) the number of studies that
collected ethnicity separately from race, and (ii) stratified analysis
of racial and ethnic breakdown of large ( >100 participants) studies
versus small-to-medium-scale studies ( ≤100participants).
3.3 Survey
While all papers in our final corpus reported their participants’ race
and ethnicity, many in the final corpus left the reason and process
of collecting the race and ethnicity of their participants implicit .
We therefore conducted an additional survey to find out why re-
searchers collect racial and ethnic data, and to learn about potential
challenges they may have experienced. For each publication in
the final curated corpus, we emailed the first and senior authors
with a list of open-ended questions on why they collected race and
ethnicity information of their participants.
In addition to the responses from the authors, we note that some
authors already highlighted the importance of considering race and
ethnicity for the piece of technology under study as part of their
discussion sections. For instance, research on virtual reality and
gaming made up a substantial portion of the corpus: by surveying
gamers from a diverse race and ethnicity background, Passmore
et al. [35] established “ significant differences between players of color
and White players on perception of racial norms in gaming, effects
of behavior, emotions, player satisfaction, engagement, and beliefs
stemming from a lack of diversity. ” Moreover, they emphasized
that the diverse recruitment amounted to “ higher dissatisfaction [in
diversity in digital games] than previous research .”
4 RESULT
4.1 RQ1: Who are the study participants in the
curated CHI corpus?
In total, we analyzed 340 manuscripts, of which 93 (27.3%) provided
descriptive statistics on the racial and ethnic breakdown of their
study participants. Our analysis showed that only 93 (2.4%) of 3,910
CHI papers included descriptive information of participants’ race
and ethnicity. This is likely an undercount given that the final
corpus only included studies with the specified keywords.
Out of the 93 manuscripts, the median number of reported racial
and ethnic groups is 4 (IQR: 3–5). Only a small number (17; 18.2%) of
studies mentioned (or was inferred of) using two separate questionsCHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA Chen et al.
for race and ethnicity. The median number of participants of the
studies in the final corpus is 28 (IQR: 18–187); the largest study
reported the racial and ethnic breakdown of 2,041 participants [ 50],
and the smallest study in our corpus had only six participants [ 15].
The aggregated studies reported 19,684 participants in total,
12,627 (64.1%) of whom are non-Hispanic White; 2,028 (10.3%) Black;
1,766 (8.9%) Hispanic; 1,327 (6.7%) Asian; and 1,939 (4.6%) Others
(with 205 Mixed races and 98 American Indian or Alaska Natives).
By contrast, according to the estimated demographic data by the
U.S. census for 2015–2019, 60.7% of the population in the U.S. is non-
Hispanic White; 12.3% Black; 18% Hispanic; 5.5% Asian; and 3.5%
Others (2.4% Mixed and 0.7% American Indian or Alaska Natives).
Regarding the U.S.-based FDA drug trials during 2015 and 2019, non-
Hispanic White accounted for 64.5% of the participants, followed
by 16% for Black and 15% for Hispanic. Asians and Other groups
account for 2% and 3.5% of the trial participants, respectively.
Racial and ethnic compositions from the three different sources
(CHI, U.S. Census, and the FDA drug trials) are displayed in Figure 1.
We see that compared to the U.S. Census, CHI studies in our final
corpus have slightly more non-Hispanic Whites and slightly less
Hispanics. In addition, Figure 1 suggests that participants in neither
CHI studies nor FDA trials are representative of the aggregated
U.S. demographics. However, we note that many CHI studies ac-
tively recruited a representative sample of their interest, which
may or may not agree with the aggregated demographics of the U.S.
For instance, Lopez et al . [27] was a non-Hispanic-White-focused
studies, and Dosono and Semaan [10] specifically looked at the en-
gagement and dynamics of the Asian American and Pacific Islander
online communities. As a result, neither studies resembles the U.S.
demographics by design, rather than by omission.
We also looked at longitudinal trend of the compositions of
reported racial and ethnic groups across the six years of CHI pro-
ceedings. Overall, the racial and ethnic compositions of study par-
ticipants appear stable over the course of six years, with a more
noticeable increase of non-White participants from 2020 onwards.
Figure 2 displays the racial and ethnic composition over the six
years, stratified by the size of the study, where a study is classified
as “large” if it has more than 100 participants and “small-to-medium”
otherwise. We see that large-scale studies tend to have more White
participants. This is partly due to the use of online platforms (e.g.,
Twitter or Mechanical Turk) for participant recruitment, which has
been known to skew towards White samples [ 26,52]. On the other
hand, small-to-medium studies are more likely to target specific
populations of interest (e.g., studying particular technology of in-
terest in low-income neighbourhoods or among Black females). As
a result, small-to-medium studies might appear more racially and
ethnically diverse than larger studies.
4.2 RQ2: Why are race and ethnicity of study
participants collected in the curated CHI
corpus?
Almost all of the authors in our final corpus and survey sample were
affiliated with an U.S. institution at the time of writing. Responses
to our survey ( 𝑛=15) are summarized in Table 1. Because the
authors could list multiple options in their open-ended responses,
frequencies of the categories add up to over 15.
Figure 1: Racial and ethnic compositions of participants (in
five groups) from three different sources: CHI proceedings
(2016–2021, leftmost); demographics projection of the U.S.
census (2015–2019, middle); participants of U.S.-based FDA
drug trials (2015–2019, rightmost).
Figure 2: Racial and ethnic compositions of study partici-
pants from CHI proceedings between 2016 and 2021, by year
and study size (large, >100 participants; small-to-medium,
≤100participants).
Occurrence
Why
External validity 8
Targeted studies 4
Motivated by prior work 8
External requirement 2
Motivate future studies 4
Table 1: A summary of surveyed authors’ responses. Note
that multiple reasons and sources are allowed. Therefore,
occurrences in each individual category could add up to more
than 15. The categories are determined through a qualitative
coding of the responses.Collecting and Reporting Race and Ethnicity Data in HCI CHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA
The most common reason (“Why” in Table 1) for collecting and
reporting racial and ethnic information is external validity , that
is, the degree to which the conclusion in one study would hold
for other persons in other places and times [ 13]. For instance, one
surveyed researcher noted in their response that “ If my data is
really only from a sample of White people, then I need to acknowl-
edge that as a limitation of the study and ensure that my analysis
is contextualized in that particular identity .” A majority of the sur-
veyed researchers also named prior work as a driving factor. As an
example, one response noted that “We were specifically interested
in experiences of intra-community marginalization , which includes
systemic biases such as racism , and we wanted to ensure that our
sample could capture such dynamics.” In addition, the interplay
between race, racism, and socioeconomic class in the U.S. motivates
some researchers to “always collect these data” because when it
comes to disparities as they affect technology, “ race and income
are so woefully correlated in this country [the U.S.] (and others) — it
was important to collect racial/ethnic information. ” Only two out
of 15 responses mentioned “external requirement” as the primary
reason for collecting and reporting participants’ race and ethnic-
ity. Nonetheless, one response stated that “ I was in a Biomedical
Informatics program, and health studies often have people collect this
data (perhaps tied to NIH funding requirements) ”, which speaks to
the possibility of leveraging training from related disciplines to
improve the collection and report of race in HCI.
5 DISCUSSION
The primary goal of our work is to understand the race and eth-
nicity data in HCI from the following aspects: (i) who are the HCI
study participants in terms of race and ethnicity (RQ1); and (ii) why
are race and ethnicity collected (RQ2). In terms of “who”, our anal-
ysis revealed that, for studies published in CHI between 2016 and
2021, less than 3% included detailed race and ethnicity information
about their study participants. Among those studies that are based
in the United States, about 64% of total participants identified as
non-Hispanic White. By contrast, 9% and 10% identified as Hispanic
and non-Hispanic Black, respectively. Regarding “why”, we found
that for many of our participants (i.e., authors whose publications
detailed race and ethnicity of their research participants), the theme
of their work has a deep connection to race and ethnicity, which
makes the racial and ethnic diversity of their participants an inte-
gral part of their studies. Other motivating factors to collect this
information are to increase a study’s external validity, achieve a
more representative sample, or allow future research.
Our study is also subject to several limitations. One limitation
is the scope of the discussion of race and ethnicity: the paper and
existing work surveyed within are based on the racial and ethnic
context of the United States. In part, this is due to the vast collection
of existing research on race and ethnicity in the U.S. Moreover,
given the high research output of U.S.-based HCI researchers, we
hope that our work will serve as a proof-of-concept for future
conversations about race and ethnicity in HCI studies more globally.
In terms of research methodology, our sampling could be sub-
ject to selection bias — published papers in CHI proceedings are
a small subset of the broader HCI research outputs, and limiting
publications to the past six years also potentially confounds ourfinding with the longitudinal trend of research in race and eth-
nicity in HCI. For instance, more recent research outputs might
have more discourse on race and ethnicity [ 16]. Our approach to
corpus curation can also lead to an undercount: there is an array
of excellent work in CHI that discuss racial and ethnic informa-
tion qualitatively, and therefore do not provide racial and ethnic
breakdown of participants. Such work is likely to be omitted in
our curation process, despite the relevance. Furthermore, as the
primary intention of this work was to start a discussion on race
and ethnicity data collection, we did not prioritize an exhaustive,
iterative refining of our corpus. Therefore, the reported results
on the final corpus of papers are likely an underestimate of the
CHI publications that collected and reported participants’ race and
ethnic information. Moreover, regarding the survey results, the 15
researchers who provided prompt responses to our inquiries might
not be a representative sample of HCI researchers. For instance,
47% of the researchers who participated in our survey used separate
questions to collect race and ethnicity, as opposed to less than 20%
of the researchers in the entire final corpus.
6 CONCLUSION AND FUTURE WORK
As HCI continues to engage with a racially- and ethnically-diverse
population of users, understanding the current practice of collecting
race and ethnicity of participants in HCI research takes on high
importance. Through a systematic review of published CHI papers
and follow-up surveys with selected authors, we found that few
published papers collected and reported their participants’ race and
ethnicity. Among those authors who did collect this information, the
primary motivations include (i) strengthening the external validity
of the study, and (ii) addressing the established disparities in the
uptake and use of technologies between different racial groups.
Our findings reveal several important directions of future work.
Firstly, CHI is a global community and reporting on the ethnic-
ity of participants outside of the U.S. has been steadily increasing
(e.g., David Bowman et al . [9], Koushki et al . [23] , Randhawa et al .
[38]). Extending our discussions to a more global context will cham-
pion the call for inclusiveness and representation of non-Western
samples in the HCI research community. In addition, even in the U.S.
context, the nuance of racial groups are not necessarily captured
by the established categories used in the U.S. census. For instance,
although Middle Eastern and North African Americans are classi-
fied as White in the U.S. census, a sizable number believe that they
are not treated or perceived as Whites, and that such classification
might perpetuate further harm [ 28,29,40]. Moreover, depending
on the nature of the study, categories used in the U.S. Census such
as Asian Americans and Pacific Islanders do not necessarily cap-
ture the underlying diversity of the group, and researchers have
called for more granular categories to reflect and communicate
participants’ identities [17, 18, 21].
Another avenue of research is to investigate the challenges en-
countered in decisions around race and ethnicity data collection
and analysis, especially among the researchers who decided notto
collect and report such data. For instance, a systematic summary
of the primary barriers (e.g., privacy and legal concerns, lack of
systematic categories for large-scale international studies) couldCHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA Chen et al.
inform future efforts on providing resources and designing tools to
overcome these barriers.
Finally, in future work, we plan to outline a few recommenda-
tions which will serve to further the conversations on whether the
data on race and ethnicity should be collected, and in what circum-
stances. Critically, we want to highlight the importance of a deeper
and broader consideration of racial and ethnic data collection and
analysis in HCI, and certainly within the research team — as long
as racial and ethnic categories continue to govern social, political,
and cultural interactions, collecting and analyzing racial and ethnic
data fits squarely within the agenda of HCI.
REFERENCES
[1]Julio Abascal and Colette Nicolle. 2005. Moving towards inclusive design guide-
lines for socially and ethically aware HCI. Interacting with Computers 17, 5 (Sept.
2005), 484–505.
[2]American Psychological Association. 2019. Publication Manual of the Amer-
ican Psychological Association: 7th Edition, 2020 Copyright (7 ed.). American
Psychological Association.
[3]American Sociological Association. 2017. The Importance of Collecting Data
and Doing Social Science Research on Race. https://www.asanet.org/importance-
collecting-data-and-doing-social-science-research-race. Accessed: 2021-8-5.
[4]Margo Anderson and Stephen E Fienberg. 2000. Race and ethnicity and the
controversy over the US Census. Current Sociology 48, 3 (2000), 87–110.
[5]Jack M Bloom. 2019. Class, Race, and the Civil Rights Movement, Second Edition .
Indiana University Press.
[6]Center for Drug Evaluation and Research. 2019. Drug Trials Snapshots . Accessed:
2021-3-8.
[7]Derrick L Cogburn. 2003. HCI in the so-called developing world: what’s in it for
everyone. Interactions 10, 2 (March 2003), 80–87.
[8]Patricia Hill Collins and Sirma Bilge. 2020. Intersectionality . John Wiley & Sons.
[9]Nicholas David Bowman, Jihhsuan Tammy Lin, and Chieh Wu. 2021. A Chinese-
Language Validation of the Video Game Demand Scale (VGDS-C): Measuring
the Cognitive, Emotional, Physical, and Social Demands of Video Games. In
Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems .
Association for Computing Machinery, New York, NY, USA, 1–10.
[10] Bryan Dosono and Bryan Semaan. 2019. Moderation Practices as Emotional
Labor in Sustaining Online Communities: The Case of AAPI Identity Work on
Reddit. In Proceedings of the 2019 CHI Conference on Human Factors in Computing
Systems . Association for Computing Machinery, New York, NY, USA, 1–13.
[11] Susan M Dray, David A Siegel, and Paula Kotzé. 2003. Indra’s Net: HCI in the
developing world. Interactions 10, 2 (March 2003), 28–37.
[12] Tracy Frey and Roxanne K. Young. 2020. Race/Ethnicity. AMA Manual of
Style. https://www.amamanualofstyle.com/view/10.1093/jama/9780190246556.
001.0001/med-9780190246556-chapter-11-div2-23. Accessed: 2021-8-5.
[13] Darren Gergle and Desney S Tan. 2014. Experimental Research in HCI. In Ways
of Knowing in HCI , Judith S Olson and Wendy A Kellogg (Eds.). Springer New
York, New York, NY, 191–227.
[14] Maureen T Hallinan. 2001. Sociological Perspectives on Black-White Inequalities
in American Schooling. Sociology of Education 74 (2001), 50–70.
[15] Foad Hamidi, Lydia Stamato, Lisa Scheifele, Rian Ciela Visscher Hammond, and
S Nisa Asgarali-Hoffman. 2021. “Turning the Invisible Visible”: Transdisciplinary
Bioart Explorations in Human-DNA Interaction. In Proceedings of the 2021 CHI
Conference on Human Factors in Computing Systems . Association for Computing
Machinery, New York, NY, USA, 1–15.
[16] Julia Himmelsbach, Stephanie Schwarz, Cornelia Gerdenitsch, Beatrix Wais-
Zechmann, Jan Bobeth, and Manfred Tscheligi. 2019. Do We Care About Diversity
in Human Computer Interaction: A Comprehensive Content Analysis on Diver-
sity Dimensions in Research. In Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems (Glasgow, Scotland Uk) (CHI ’19) . Association for
Computing Machinery, New York, NY, USA, 1–16.
[17] Ariel T Holland and Latha P Palaniappan. 2012. Problems with the collection
and interpretation of Asian-American health data: omission, aggregation, and
extrapolation. Annals of Epidemiology 22, 6 (June 2012), 397–405.
[18] Institute of Medicine (US) Subcommittee on Standardized Collection of
Race/Ethnicity Data for Healthcare Quality Improvement. 2014. Race, Ethnic-
ity, and Language Data: Standardization for Health Care Quality Improvement .
National Academies Press (US), Washington (DC).
[19] C P Jones. 2001. Invited commentary: “race, ” racism, and the practice of epidemi-
ology. American Journal of Epidemiology 154, 4 (Aug. 2001), 299–304; discussion
305–6.
[20] Camara Phyllis Jones, Benedict I Truman, Laurie D Elam-Evans, Camille A Jones,
Clara Y Jones, Ruth Jiles, Susan F Rumisha, and Geraldine S Perry. 2008. Using“socially assigned race” to probe white advantages in health status. Ethnicity &
Disease 18, 4 (2008), 496–504.
[21] Bliss Kaneshiro, Olga Geling, Kapuaola Gellert, and Lynnae Millar. 2011. The
challenges of collecting data on race and ethnicity in a diverse, multiethnic state.
Hawaii medical journal 70, 8 (Aug. 2011), 168–171.
[22] J S Kaufman and R S Cooper. 2001. Commentary: considerations for use of
racial/ethnic classification in etiologic research. American Journal of Epidemiology
154, 4 (Aug. 2001), 291–298.
[23] Masoud Mehrabi Koushki, Borke Obada-Obieh, Jun Ho Huh, and Konstantin
Beznosov. 2021. On Smartphone Users’ Difficulty with Understanding Implicit
Authentication. In Proceedings of the 2021 CHI Conference on Human Factors in
Computing Systems . Association for Computing Machinery, New York, NY, USA,
1–14.
[24] Nancy Krieger, Jaquelyn L Jahn, and Pamela D Waterman. 2017. Jim Crow and
estrogen-receptor-negative breast cancer: US-born black and white non-Hispanic
women, 1992-2012. Cancer Causes & Control 28, 1 (Jan. 2017), 49–59.
[25] Sharon M Lee. 1993. Racial classifications in the US census: 1890–1990. Ethnic
and racial studies 16, 1 (Jan. 1993), 75–94.
[26] Kevin E Levay, Jeremy Freese, and James N Druckman. 2016. The Demographic
and Political Composition of Mechanical Turk Samples. SAGE Open 6, 1 (Jan.
2016).
[27] Sarah Lopez, Yi Yang, Kevin Beltran, Soo Jung Kim, Jennifer Cruz Hernandez,
Chelsy Simran, Bingkun Yang, and Beste F Yuksel. 2019. Investigating Implicit
Gender Bias and Embodiment of White Males in Virtual Reality with Full Body
Visuomotor Synchrony. In Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems . Association for Computing Machinery, New York,
NY, USA, 1–12.
[28] Neda Maghbouleh, Ariela Schachter, and René D Flores. 2022. Middle Eastern
and North African Americans may not be perceived, nor perceive themselves, to
be White. PNAS 119, 7 (Feb. 2022).
[29] Patrick L Mason and Andrew Matella. 2014. Stigmatization and racial selection
after September 11, 2001: self-identity among Arab and Islamic Americans. IZA
Journal of Migration 3, 1 (Oct. 2014), 1–21.
[30] National Institutes of Health. 2001. NOT-OD-01-053: NIH POLICY ON REPORT-
ING RACE AND ETHNICITY DATA: SUBJECTS IN CLINICAL RESEARCH.
https://grants.nih.gov/grants/guide/notice-files/NOT-OD-01-053.html. Accessed:
2021-8-5.
[31] National Science Foundation. 2017. Technical Notes. https://www.nsf.gov/
statistics/2017/nsf17310/technical-notes.cfm. Accessed: 2021-8-5.
[32] Anna Offenwanger, Alan John Milligan, Minsuk Chang, Julia Bullard, and Dong-
wook Yoon. 2021. Diagnosing Bias in the Gender Representation of HCI Research
Participants: How it Happens and Where We Are. In Proceedings of the 2021 CHI
Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI ’21,
Article 399) . Association for Computing Machinery, New York, NY, USA, 1–18.
[33] Ihudiya Finda Ogbonnaya-Ogburu, Angela D R Smith, Alexandra To, and Kentaro
Toyama. 2020. Critical Race Theory for HCI. In Proceedings of the 2020 CHI
Conference on Human Factors in Computing Systems . Association for Computing
Machinery, New York, NY, USA, 1–16.
[34] Newton G Osborne and Marvin D Feit. 1992. The Use of Race in Medical Research.
JAMA: the journal of the American Medical Association 267, 2 (Jan. 1992), 275–279.
[35] Cale J Passmore, Max V Birk, and Regan L Mandryk. 2018. The Privilege of
Immersion: Racial and Ethnic Experiences, Perceptions, and Beliefs in Digital
Gaming. In Proceedings of the 2018 CHI Conference on Human Factors in Computing
Systems (Montreal QC, Canada) (CHI ’18) . Association for Computing Machinery,
New York, NY, USA, 1–19.
[36] Pew Research Center. 2015. Multiracial in America: Proud, Diverse and Growing
in Numbers. https://www.pewsocialtrends.org/wp-content/uploads/sites/3/2015/
06/2015-06-11_multiracial-in-america_final-updated.pdf. Accessed: 2021-6-25.
[37] Race in HCI Collective, Angela D R Smith, Adriana Alvarado Garcia, Ian Arawjo,
Audrey Bennett, Khalia Braswell, Bryan Dosono, Ron Eglash, Denae Ford, Daniel
Gardner, Shamika Goddard, Jaye Nias, Cale Passmore, Yolanda Rankin, Naba
Rizvi, Carol F Scott, Jakita Thomas, Alexandra To, Ihudiya Finda Ogbonnaya-
Ogburu, and Marisol Wong-Villacres. 2021. Keepin’ it real about race in HCI.
Interactions 28, 5 (Aug. 2021), 28–33.
[38] Shan M Randhawa, Tallal Ahmad, Jay Chen, and Agha Ali Raza. 2021. Karamad: A
Voice-based Crowdsourcing Platform for Underserved Populations. In Proceedings
of the 2021 CHI Conference on Human Factors in Computing Systems . Association
for Computing Machinery, New York, NY, USA, 1–15.
[39] Yolanda A Rankin and Jakita O Thomas. 2019. Straighten up and fly right:
Rethinking intersectionality in HCI research. Interactions 26, 6 (2019), 64–68.
[40] Helen Hatab Samhan. 2001. Who Are Arab Americans?
[41] Morgan Klaus Scheuerman, Katta Spiel, Oliver L. Haimson, Foad Hamidi, and
Stacy M. Branham. 2021. HCI Gender Guidelines. https://www.morgan-klaus.
com/gender-guidelines.html. Accessed: 2021-8-6.
[42] Ari Schlesinger, W Keith Edwards, and Rebecca E Grinter. 2017. Intersectional
HCI: Engaging Identity through Gender, Race, and Class. In Proceedings of the
2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado,
USA) (CHI ’17) . Association for Computing Machinery, New York, NY, USA,Collecting and Reporting Race and Ethnicity Data in HCI CHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA
5412–5427.
[43] Jonathan Schwabish and Alice Feng. 2020. Applying Racial Equity Awareness in
Data Visualization. (Aug. 2020).
[44] Angela D R Smith, Alex A Ahmed, Adriana Alvarado Garcia, Bryan Dosono,
Ihudiya Ogbonnaya-Ogburu, Yolanda Rankin, Alexandra To, and Kentaro Toyama.
2020. What’s Race Got To Do With It? Engaging in Race in HCI. In Extended
Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems
(Honolulu, HI, USA) (CHI EA ’20) . Association for Computing Machinery, New
York, NY, USA, 1–8.
[45] Katta Spiel, Oliver L Haimson, and Danielle Lottridge. 2019. How to do better
with gender on surveys: a guide for HCI researchers. Interactions 26, 4 (June
2019), 62–65.
[46] Simone Stumpf, Anicia Peters, Shaowen Bardzell, Margaret Burnett, Daniela
Busse, Jessica Cauchard, and Elizabeth Churchill. 2020. Gender-Inclusive HCI
Research and Design: A Conceptual Review . Now Foundations and Trends.
[47] Christian Sturm, Alice Oh, Sebastian Linxen, Jose Abdelnour Nocera, Susan Dray,
and Katharina Reinecke. 2015. How WEIRD is HCI? Extending HCI Principles to
other Countries and Cultures. In Proceedings of the 33rd Annual ACM Conference
Extended Abstracts on Human Factors in Computing Systems (Seoul, Republic ofKorea) (CHI EA ’15) . Association for Computing Machinery, New York, NY, USA,
2425–2428.
[48] Kentaro Toyama. 2010. Human–Computer Interaction and Global Development.
Foundations and Trends ®in Human–Computer Interaction 4, 1 (2010), 1–79.
[49] US Census Bureau. 2019. National Demographic Analysis Tables: 2020 . Accessed:
2021-3-8.
[50] Tavish Vaidya, Daniel Votipka, Michelle L Mazurek, and Micah Sherr. 2019.
Does Being Verified Make You More Credible? Account Verification’s Effect on
Tweet Credibility. In Proceedings of the 2019 CHI Conference on Human Factors in
Computing Systems . Association for Computing Machinery, New York, NY, USA,
1–13.
[51] Judy van Biljon and Karen Renaud. 2019. Human-Computer Interaction for
Development (HCI4D): The Southern African Landscape. In Information and
Communication Technologies for Development. Strengthening Southern-Driven
Cooperation as a Catalyst for ICT4D . Springer International Publishing, 253–266.
[52] Kelly Walters, Dimitri A Christakis, and Davene R Wright. 2018. Are Mechanical
Turk worker samples representative of health status and health behaviors in the
U.S.? PloS one 13, 6 (June 2018), e0198835.
[53] Kim M Williams. 2006. Mark One or More . University of Michigan Press.CHI ’22 Extended Abstracts, April 29-May 5, 2022, New Orleans, LA, USA Chen et al.
                                 * Keywords: (i) ``race'' OR ``racial'' OR ``ethnicity'' AND (ii) ``Hispanic'' OR ``African American'' OR ``Asian'' OR ``Caucasian''. Articles not containing these keywords are excluded using the automatic search tools of the ACM digital library. ** Since an overwhelming majority of the articles that reported detailed racial and ethnic data recruited their participants from the U.S., we adopted this criterion to focus our discussion of race and ethnicity in the U.S.      Published articles from 2016-2021 CHI proceedings available at ACM digital library (n=3,910)  Articles screened for keywords* (n = 340) Articles excluded (n = 3,670) Articles assessed manually for (i)  whether detailed racial and ethnic data were reported for study participants; and (ii) whether the participants are based in the U.S. (n = 93) Articles excluded (n = 247).  Reasons for exclusion: • No participants in the study • No race and ethnicity information provided • Only has White versus non-White categories • Non-U.S. based participants** Studies included in the final corpus (n = 93) Identification of final corpus from 2016-2021 CHI proceedings 
Identification 
Screening  
Included 
Figure 3: The flow of information through different phases of the corpus curation process as described in Section 3.1. We
displayed the inclusion and exclusion criteria, as well as the final number resulting publications of each stage.