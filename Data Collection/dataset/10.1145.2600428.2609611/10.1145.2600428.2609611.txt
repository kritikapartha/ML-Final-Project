A Mathematics Retrieval System for Formulae in Layout
Presentations
Xiaoyan Lin, Liangcai Gao∗,
XuanHu,ZhiTang
Institute of Computer Science
& Technology, Peking
University, Beijing, China
{linxiaoyan, glc, xuan.hu,
tangzhi}@pku.edu.cnYingnan Xiao
School of Software
Engineering, Beijing University
of Posts and
Telecommunications, Beijing,
China
lxyxynt@bupt.edu.cnXiaozhong Liu
Department of Information and
Library Science, Indiana
University, Bloomington, IN,
USA
liu237@indiana.edu
ABSTRACT
The semantics of mathematical formulae depend on
their spatial structure, and they usually exist in layout
presentations such as PDF, LATEX, and Presentation
MathML, which challenges previous text index and retrieval
methods. This paper proposes an innovative mathematics
retrieval system along with the novel algorithms, which
enables eﬃcient formula index and retrieval from both
webpages and PDF documents. Unlike prior studies, which
require users to manually input formula markup language
as query, the new system enables users to “copy” formula
queries directly from PDF documents. Furthermore, by
using a novel indexing and matching model, the system is
aimed at searching for similar mathematical formulae based
on both textual and spatial similarities. A hierarchical
generalization technique is proposed to generate sub-trees
from the semi-operator tree of formulae and support
substructure match and fuzzy match. Experiments based
on massive Wikipedia and CiteSeer repositories show that
thenewsystem along with novelalgorithms, comparing with
two representative mathematics retrieval systems, provides
more eﬃcient mathematical formula index and retrieval,
while simplifying user query input for PDF documents.
Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval ]: Information
Search and Retrieval
Keywords
Mathematical Information Retrieval; Structure Matching;
Layout Presentation; Scientiﬁc Information Extraction
1. INTRODUCTION
Mathematical formulae are commonly used
in various disciplines, such as STEM (Science, Technology,
∗Liangcai Gao is the corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’14, July 6–11, 2014, Gold Coast, Queensland, Australia.
Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00.
http://dx.doi.org/10.1145/2600428.2609611.Engineering, and Mathematics) research and education.
For ﬂexible display of mathematical concepts with high
quality in various environments, mathematical formulae are
usually presented in layout presentations, such as LATEX,
Presentation MathML, or PDF documents. Due to the
lack of semantic structures, the math formulae are diﬃcult
to be indexed, retrieved and consumed. Meanwhile, it is
diﬃcult for users to input formulae as queries to address
their information need. Mathematics retrieval, targeting
at facilitating the access, retrieval and discovery of math
resources, becomes increasingly needed in many scenarios.
For example, many traditional courses or massive open
online courses (MOOCs) release thecourse resources (books,
lecture notes and exercises, etc) in PDF or HTML. In
these resources, mathematical formulae could be the most
challenging part [8]. However, it is diﬃcult for students
to ﬁnd useful complementary materials according to the
formula that they encounter in the learning materials. On
the other hand, users cannot directly obtain the formulae as
queries by text copy&paste from PDF documents, which is
an important search behavior in classic web search engines
[1]. Even after users take eﬀorts to type out the LATEX codes
oftheformulae, theymightnotprobablygettheidealresults
from the traditional text-based search engines. In that,
classic search engines cannot properly index and retrieve
mathematical formulae.
Although mathematics retrieval is useful for diﬀerent
applications, practical systems are still quite sparse. It is
mainlybecausemathematical formulaeare highlystructured
and domain-speciﬁc, while most math formulae available in
existing information system are either in layout presentation
or unstructuredformat (e.g., PDF). This problem challenges
the construction of mathematics retrieval systems in query
interface, normalization, indexing and ranking [16]:
Query interface : Unlike text-based search, mathematics
retrieval system usually takes math formulae as queries. A
query interface, which needs to concern how to input the
highlystructuredformulae intothesearchengine, isessential
to popularize the system. The currentsearch engines require
users to know the classiﬁcation, or name of a formula or
using an editor or string encoding (e.g., LATEX) to enter
formulae [7]. However, these interfaces would cost extra
time and eﬀorts of users to input query formulae. Moreover,
for the junior users, learning encoding query language is a
challenging task.
Normalization : Normalization is essential to ensure all
697the equivalent math formulae with diﬀerent presentations
or
transformations can be recalled. Diﬀerent from word
stemming and thesaurus operation in text retrieval, formula
normalization should overcome variation in variables,
constants, spatial layouts or even semantics among
equivalentformulae. Forinstance,“ a+b/c”and“y/z+x”,“a
b”
an
d“a/b”,“x−2”and“1
x2”havediﬀerentlayoutpresentations
while presenting the same meaning.
Indexing and ranking : Intuitively, spatial layouts or
semantics of math formula can be expressed or understood
in tree-structures. In order to accurately calculate
the structural similarities of formulae, attributes of tree
structures are commonly considered, such as sub-trees and
levels. For example, formulae containing the same main
structure with diﬀerent sub-trees (e.g., a+b×yvs.x+y),
and formulae containing diﬀerent main structure with the
same sub-trees (e.g., a+b×yvs.b×y). A major
diﬃcultywithextractingstructuralattributesfrom formulae
in layout presentation is that, the layout presentation
usually contains limited semantics about the formulae. Take
the three expressions as mentioned previously, the LATEX
presents all symbols linearly without denoting the priority
of operators. Moreover, how to calculate the similarity score
according to the attributes of tree structures remains an
open problem, because the motivations of diﬀerent users of
the mathematics retrieval systems vary according to their
background and speciﬁc tasks [18].
In order to solve the aforementioned challenges, in this
study, we propose a publicly available mathematics retrieval
system1towards formulae in layout presentations. The
contribution of this study is threefold: 1) Query interface :
A novel query input interface is proposed to enable users
to “copy” formula queries directly from PDF documents;
2)Normalization : A semantic enrichment technique is
proposed to extract the structural and semantic information
from the layout presentations of formulae. Additionally,
normalization of operand orders and hierarchical structure
generalization are proposed to support more reasonable
fuzzy matching and similarity calculation; 3) Indexing and
ranking: Eﬀective online query is implemented by proposing
theindexingtechniquetowardsbothoriginal andgeneralized
sub-structures of formulae. In addition, we propose the
novel similarity function, which addresses hierarchical and
fuzzy matching between formulae. Moreover, the relevant
score between query formula and a document (webpage or
PDF)is calculated based uponthehybridofa representative
formula and a set of relevant formulae.
2. RELATED WORK
Mathematics retrieval has been researched since 2003 [9],
and more than ten systems are reported. We summarize
these systems according to the essential aspects of
constructing a mathematics retrieval system in Table 1 and
analyze the relevant approaches on query interface, formula
presentation, indexing and ranking techniques as follows.
2.1 Query Interface
The existing user interfaces can be classiﬁed into four
categories: 1)The ﬁrst type of interface provides detailed
taxonomy of mathematics (e.g., Wolfram2) to support
1http://www.icst.pku.edu.cn/cpdp/wikimirs2/
2http://mathworld.wolfram.comretrieving formulae and related information in the function
library. This interface requires users to know well about
the name or category of the query formula. 2)The
second category designs specially deﬁned query language
to capture users’ information needs (e.g., set wildcards
for subexpressions or variables)[4]. 3)The third category
provides an graphic equation editor for users to input
formulae [5, 12]. Recently, handwritten methods are
proposed to enable users to input handwritten formulae
on smartphones or tablets [7]. These methods still cost
users’ extra eﬀorts to obtain the formula query and seems
unbearable when the formula happens to be complicated.
4)The last category of interface requires users to input
speciﬁc encodings of formulae such as LATEX or MathML.
This is used by most of the existing systems [9, 15] and
is considered as the most convenient interface given the
markups of query formula are already available to the user.
Similarly with handwritten input, typing out the markups
of the query formula manually is quite time-consuming and
troublesome, especially for the users know little grammars
of these markups. To settle this problem, a query input
interface is proposed to supportusers to inputqueryformula
via clipping the formula region from PDF documents.
2.2 Formula Presentation
Formula presentation denotes the internal format of
formulae of a mathematics retrieval system. It is important
since it determines the compatibility of a mathematics
retrieval system to the existing data sources. Early
researches of mathematics retrieval focus on semantic
presentations(e.g., ContentMathML,OpenMath)[5], which
mark up the semantic meanings of formulae. However,
in practice, most math formula resources are presented in
layout presentations (e.g., Presentation MathML, LATEX)
in the webpages or in unstructured forms (e.g., PDF) in
documents. For instance, Wikipedia encodes formulae in
webpages using LATEX. In digital libraries, math concepts
are encoded as unstructured symbols in PDF documents.
Meanwhile, formula presentation determines the amount
of information that the mathematics retrieval system can
rely on. Since Presentation MathML, LATEX or PDF only
contain limited spatial layouts andfew semantic information
offormulae, existing mathematics retrieval systemsbased on
these layout presentations can only support exact matching
[11] or consider little about the structure matching [2, 14,
15]. To address this problem, this paper proposes to enrich
structural and semantic information of formulae in layout
presentations, so as to realize structure and fuzzy matching
in mathematics retrieval.
2.3 Indexing
The main indexing techniques of mathematics retrieval
include text-based and tree-based, as classiﬁed in Table 1.
The idea of text-based indexing techniques [9, 10, 11] is
to convert math formula markups into plain text strings, so
that they can be indexed using existing text-based indexing
tools like Lucene. Because mathematical formulae are
highly symbolic and structured, the transformation from
structural formulae into plain text strings mainly focuses
on how to encode structures in text strings and normalize
diﬀerent presentations of formulae. Miller et al. convert
all non-alphanumeric symbols in LATEX into alphanumeric
symbols and normalize the order of operands into a
698Table 1: Comparison of Mathematical Information Retrieval Sy stems1
Systems/Methods Interface Presentation Normalization Matching Ranking Corpus
Text-based indexing
DLMF[9] LATEX LATEX Order Exact tf-idf DLMF
Mathdex[10] PMML PMML Variables Similar tf-idf& weights arXiv; Wikipedia
EgoMath[11] LATEX,text PMML Variables,constants Exact tf-idf Wikipedia
Tree-based indexing
MathWebSearch[5] Editor CMML / Similar / Connexions;Wolfram
MIaS[15] LATEX,PMML PMML Order,variables,
co
nstantsSimilar tf-idf& weights arXiv
[14] LATEX LATEX Order,variables Similar Similarity of
ma
tched setsarXiv
WikiMirs[2] LATEX LATEX Variables Similar tf-idf& weights Wikipedia
Other
[13] CMML CMML Variables Similar Similarity of
fe
ature setsConstructed dataset
MASE[12] Editor,text LATEX / Similar tf-idf w ith
learned weightsMath Overﬂow
[4] PMML,query
la
nguagePMML / Similar Edit distance,
pa
ttern matchWikipedia; DLMF
1“Order”denotes the order of operands. “PMML”and“CMML”denote Presentation and Content MathML, respectively.
canonical form [9]. A similar method is proposed by
Misutka et al. [11] with improvement via normalization of
variables and constants. The structures of formulae are lost
in those methods. Aimed at matching formula structures
in the text-based indexing methods, Miner et al. [10] index
n-gram terms, which are substructures with no more than n
successive tags, meaning only substructure with no more
thannnodes are indexed, and high-level structures or
complex structures in the formula are rarely considered.
In tree-based methods, attributes of formula tree
structures (e.g., substructures or paths) are extracted as
index terms. In order to support substructure and fuzzy
matching, a straightforward wayis to indexall substructures
offormulae with termattributes(e.g., frequency, level)[15]3.
However, fuzzy match between expressions sharing high-
level structures cannot be realized. In order to
better support fuzzy match, Hu et al. [2] propose to
extract substructures from the LATEX markups considering
hierarchical generalization of substructures. Since this
method is based on formulae’s layout presentations,
the structural match between formulae encoded in one-
dimensional markups cannot be supported (will be detailed
in Section 3.4.1). In order to avoid explosive growth of
index space when indexing all substructures of formulae,
Kohlhase et al. [5]apply a substitution tree indexing
technique to index substructures of semantic formula
presentation. A substitution tree represents the structure
of all the indexed ﬁrst-order logic terms. Exact or similar
matches can be found by backtracking all nodes of the
substitution tree using diﬀerent strategies. However, the
substitution tree in [5] is built upon operator tree of
formula, which is diﬃcult to extract from formulae in layout
presentations. To overcome this, Schellenberg et al. [14]
employ the substitution tree indexing technique to index
layout presentations of formulae. However, the insertion
bias introduced in their paper has a signiﬁcant impact
on the results. To address the problem of supporting
meaningful substructure and fuzzy match of formulae in
layout presentations, a novel index technique with semantic
enrichment and ﬁne-grained hierarchical generalization is
proposed in this paper.
3https://mir.fi.muni.cz/mias/There are other indexing methods, which are not text-
based or tree-based. Based on Formal Concept Analysis,
Nguyen et al. [13] extract math features and index them
via constructing a mathematical concept lattice of these
features. However, the construction of concept lattice relies
on the semantic structures of formulae which are diﬃcult to
obtain from formulae in layout presentations. LATEXSearch4
and Symbolab5are related commercial systems whose
schemes are not reported publicly.
2.4 Ranking
Most text-based methods use tf-idfto calculate
similarities of formulae. Miner et al. [10] introduce weights
for terms according to their levels, lengths and complexities.
However, asonlylimitedstructureinformation offormulae is
indexed in text-based models, the structure matching score
is diﬃcult to calculate properly. Some tree-based methods
also use the modiﬁed tf-idfto calculate the matching scores
of substructures. Sojka et al. [15] introduce weights to
discriminate substructure matches in diﬀerent levels based
on the assumption that structures in higher level are more
important than those at lower levels. Hu et al. [2] introduce
weights based upon the distance of matched terms in query
and the matched formulae. A main problem with this
method is that substructures in lower level contribute more
to the similarity score while a common sense of user is to
understand a formula from high level to low level.
Besidestf-idf, some methods evaluate the similarities of
formulae according to the similarity of feature sets. Nguyen
et al. [13] index formulae in the mathematical concept
lattice structure based on similarities of feature sets of each
formula. To search for a formula, the query is inserted
into the mathematical concept lattice and similar formulae
are ranked according to their distances from the query.
However, the system is only tested upon a small dataset
including less than 500 formulae, and its query eﬃciency
has not been analyzed. In the literature [14], each formula
can be presented by a set of sub-expressions with their
attributes(e.g., contents, neighbours)presentedina 5-tuple.
Retrievedformulae are rankedaccording to theset similarity
4http://www.latexsearch.com/
5http://symbolab.com/
699Figure 1: Workﬂow of the proposed system (Dotted lines denote o nline query ﬂows and solid lines denote
oﬄine index ﬂows).
between formulae. However, the insertion bias introduced in
their paper has a signiﬁcant impact on the retrieval results.
Kamali et.al. [4] calculate the formula similarity using tree
edit distance, which cannot evaluate the structure similarity
in diﬀerent levels. Kamali et.al. [4] also propose to ﬁnd
relevant formulae using pattern matching. This method
requires users to learn speciﬁc query language to input
query“pattern”andalso requires to predeﬁnemanypatterns
manually in advance.
Diﬀerent from the existing methods, this paper proposes
a method to calculate similarity between a query formula
and a document containing multiple relevant formulae.
The proposed similarity calculation considers not only the
relevance of substructures in original forms or generalized
forms, but also distance between sub-structures.
3. THE PROPOSED SYSTEM
3.1 Overview
Figure 1 illustrates the workﬂow of the proposed system,
including six modules: user interface ,preprocessor ,tree
constructor ,tokenizer ,indexer andranker. The solid
lines denote the oﬄine workﬂow: Firstly, preprocessor
converts diﬀerent data sources into uniform internal format
(Presentation MathML). Secondly, semantics of formulae in
Presentation MathML are enriched and semi-operator trees
of formulae are constructed by tree constructor . Thirdly,
terms are extracted by tokenizer with normalization and
generalization. Lastly, the indexercalculates and stores the
statistical data (e.g. tf-idf, term level) of each term in the
inverted index ﬁles.
The dottedlines indicate theworkﬂow howa user searches
a formula (online computation): The user can input the
query by either pasting the LATEX markups or clipping the
formula region using a PDF reader plugin. Then, the query
is preprocessed into Presentation MathML and enriched
with semantics. Next, the semi-operator tree is tokenized
into terms and passed through rankerto ﬁnd the matched
terms in the index ﬁles. The relevance scores between
query and documents are calculated based on the matched
formulae in documents. Lastly, a list of ranked documents
with relevant formulae are returned to the user.
3.2 User Interface
In our system, two user interfaces are implemented to
facilitate users to input query formulae from webpages or
PDF documents. Firstly, users can input the query formula
via manually typing or pasting the LATEX markups into
the search box at the front page of the proposed system
(as shown in Figure 2(b)). For now, the system only
accepts LATEX markups, which are more easily recognized by
Figure 2: User interface of the proposed system
ex
perienced or advanced users [7]. However, this interface
turns to be clumsy and less helpful when users are searching
formulae in PDF documents. Meanwhile, this querying
strategy is not useful when users have little experience
in using LATEX. To overcome the diﬃculty of obtaining
formula query from non-structural documents like PDF, a
novel query input interface is proposed in this paper. It
enables users to obtain query formula directly from PDF via
clipping the formula region in the document. Concretely, a
plugin (as shown in Figure 2(a)) is implemented in a PDF
reader to obtain the user’s action of clipping the formula
region in the document. After the formula region is selected
using mouse, a formula structure recovering method reﬁned
from the literature [17] is deployed to analyze the layout
structure of the formula and output it as Presentation
MathML. It is worth noting that the performance of this
structure analysis method [17] is improved by utilizing
precise character information obtained from PDF. The
reader plugin is released as a publicly available tool6.
3.3 Preprocessor
The goal of the preprocessor is to identify and convert
formula markupsfrom diﬀerentsources intouniform internal
storing formats, namely Presentation MathML. The data
sources concerned in this paper include webpages and PDF
documents. Forwebpages, thepreprocessorextractsformula
markups via identifying the pre-deﬁned markup tags. For
instance, in Wikipedia, formulae are presented as LATEX
and tagged by “ <math>”. In the preprocessor, the LATEX
markups are converted into Presentation MathML using
SnuggleTeX7. For PDF documents, formula recognition
techniques are employed to identify the formula regions and
6http://www.icst.pku.edu.cn/cpdp/Co-Reader/
7http://sourceforge.net/projects/snuggletex/
700recognize their layout structures. Concretely, characters
an
d their attributes (e.g., baselines) are extracted from
documents via parsing the documents using the PDF
parser (e.g., PDFBox). The precise boundaries of the
math formulae are then detected using the reﬁned formula
identiﬁcation method proposed in [6]. Lastly, the layout
structures of formulae are analyzed and outputted as
Presentation MathML using the reﬁned formula structure
analysis algorithm proposed in [17].
3.4 Tree Constructor
A layout presentation tree can be extracted directly based
on Presentation MathML. See an example in Figure 3 c).
As discussed in Section 2.2, the drawback of mathematics
retrieval system based on Presentation MathML or LATEX
is that many useful semantic contents of formulae are lost
in layout presentations. In this paper, we ﬁrstly compare
and analyze the main diﬀerences of layout presentations
and semantic presentations of formulae, and then propose
a semantic enrichment technique in the semi-operator tree
construction process to overcome this limitation.
3.4.1 Presentation Tree vs. Semantic Operator Tree
Before discussing the diﬀerence between layout and
semantic presentations, we ﬁrst classify the relations in
presentation tree of formulae into two categories: one-
dimensional relations and two-dimensional relations. One-
dimensional relations denote the symbols are horizontally
connected, such as, expressions connected by “+”, “-”, “× ”,
etc. Two-dimensional relations describe the symbols are
connected in non-linear relations, such as, “√”, “/summationtext”. In
l
ayout presentations, most of two-dimensional relations are
equivalent to the semantic structures of the formula. In
other words, most of the two-dimensional layout relations
can be mapped or converted into semantic structures
directly. However, symbols in one-dimensional relation is
connected using the same horizontal tag (e.g., “ <mrow>”
tag in Presentation MathML). And the semantic meanings
(e.g., operator priority, operands) are unknown in the layout
presentations. Therefore, the structures and semantics in
one-dimensional relations cannot be utilized in mathematics
retrieval. This is why semantic interpretation is needed to
convert layout presentation in one-dimensional relation into
corresponding semantic presentation.
Take “(x+y)∗a
b” as an example, its layout and
semantic presentations is illustrated in Figure 3 a)-b).
The layout presentation of a fraction (in two-dimensional
relation) can be converted into its semantic presentation
using straightforward tag conversion as denoted in green
nodes in Figure 3 a)-b), while the rest of structures
(in one-dimensional relation) cannot be converted without
special semantic interpretation. In this paper, we propose
to convert layout presentations in a one-dimensional
relations into corresponding semantic presentations using
the following semantic enrichment technique.
3.4.2 Semantic Enrichment
Conversion from layout presentation to semantic
presentation has been widely researched in the area of
formula understanding [16], but satisfactory methods or
conversion tools have not been proposed yet. How to
disambiguate the meaning of symbols or structures in
semantic presentation is quite diﬃcult since contexts and
Figure 3: Layout presentation and semantic
pr
esentation of (x+y)∗a
b
se
mantic analysis are required. However, for the same
conversion problem, mathematics retrieval has a diﬀerent
goal from that of the existing formula understanding
methods [16]. Mathematics retrieval only needs to make use
of the structures and semantics of formulae (e.g., operator
priority, tree level) as much as possible and has a relatively
high tolerance of ambiguities. In addition, as discussed
above, themainproblemwithmathematicsretrievalsystems
towards formulae in layout presentations is caused by the
lost of the semantics in one-dimensional presentations.
It is found that the one-dimensional expressions can be
interpreted into the corresponding operator trees using
classic expression calculation algorithm if disambiguation is
not taken into account. The extracted operator trees are
helpful for mathematics retrieval, since the semantics (e.g.,
hierarchical structures) are recovered.
Based on the aforementioned analysis, the semantic
enrichmentiscarriedoutasfollows: Firstly, one-dimensional
presentations are found in MathML via identifying the
“<mrow>” tags. All children under “< mrow>” tags are
analyzed using classic one-dimensional expression calculator
algorithm as described as follows: 1) The contents under
“<mrow>” tags are identiﬁed as the Inﬁx Notations of
the formula. The operators, variables and constants
can be detected by tags “ <mo>”, “<mi>” and “<mn>”,
respectively. 2) A list is deﬁned to describe the priority
of operators and the Inﬁx Notations are converted into
Reverse Polish Notations (RPN) based on this list. Since
the algorithm of converting Inﬁx Notation into RPN is well-
known, details of the algorithm is not given here.
The contents under “ <mrow>” tags are replaced with a
tree, which is the semantic presentation of these contents
and is obtained by the aforementioned process. After
executing this process from the lowest level to the highest
level of the layout presentation tree recursively, a “semi-
operator” tree is obtained, as shown in Figure 3 d). In this
paper, we call it semi-operator tree rather thanoperator tree
because there still exists a few ambiguities. For instance,
implicit multiplication is not identiﬁed, such as xymay
represent x×yor a single variable. In this paper, only
later interpretation is taken. Equivalent transformation is
also not considered, e.g., x−1is equivalent to1
x, but the
conversion from x−1to1
xisnot carried out here.
3.5 Tokenizer
3.5.1 Normalization
The goal of normalization is to convert diﬀerent formulae
701with the same meaning into a uniform format, so as to
en
sure the high recall of relevant formulae. The objects
of normalization generally includes variables, constants
and order of operands. Values of variables or constants
need to be normalized, since they have little eﬀect on
the structures of expressions. Similarly, operand order of
commutative operator (e.g., +, ×) needs to be normalized
in order to ensure that the relevant formulae with diﬀerent
order of operands can be retrieved. Most mathematics
retrieval systems towards formulae in layout presentation
can only normalize variables or constants, since there is
little information about the order of operands in layout
presentations. Inthispaper, thesemi-operator treeobtained
in previous steps can be used to normalize not only
the variables or constants, but also the operand orders.
Concretely, orderof operandsis ﬁrstlynormalized as follows:
A list of commutative operators (e.g., +, ×) is predeﬁned
and the operand order of commutative operators are
normalized as follows: The semi-operator tree is traversed
level by level from bottom to top. For each internal node
(non-leaf) in each level, if it is a commutative operator,
sort the node’s children according to lexicographical order
of the linear markups of the children. In this way, the
order of operands is normalized. For instance, “C+V ×C”
and “C×V+C” will be normalized to the same expression,
“C+C×V”, where “C” and “V” are the aliases of constant
and variable, respectively.
Variables and constants are encoded in “ <mi>” and
“<mn>” tags in the semi-operator tree. They are
normalized during the generalization process in term
extractor. Speciﬁcally, the contents under these tags are
removed in the generalization process, which is detailed in
the following section.
3.5.2 Term Extractor with Generalization
Term extractor aims at extracting the index terms from
the semi-operator tree of formula. Before introducing the
term extraction method, the conventions how people read or
understand formulae are ﬁrstly analyzed: Because operator
trees of mathematical formulae are naturally hierarchical,
they are conventionally read or understood in a hierarchical
way withgeneralization stepbystep. More speciﬁcally, most
of the formulae can be viewed as expressions containing an
operator with a list of operands. Generalizing the content
of operands as an alias is commonly applied to simplify
complex structure into a concise expression. For example,√a+b
(c+d)2can be viewed as∗
∗, and then as√∗
∗2, step by step. It
is seen that generalization is an important behavior when
people understand formulae. Additionally, generalization
of substructures in low level can avoid overrating for the
substructures in low level, which is a common problem
occurring in tree-based indexing methods.
Based on the aforementioned analysis, a term extraction
algorithm with generalization is proposed towards the semi-
operator trees of formulae. In order to mimic the formula
understanding process of users and support the substructure
matching and fuzzy matching in mathematics retrieval,
each substructure and its generalized forms are extracted.
Through extracting generalized terms, formulae, which
share substructures in high level, can be matched and their
similarities can be calculated properly.
The tokenizing algorithm is described in Algorithm 1. It
generates two categories of terms, namely original termsandgeneralized terms . The original terms are generated
directly from the original sub-expressions of the formulae.
The generalized terms are generated from the fuzzy sub-
expressions, so as to describe the sketch of the expression.
For each term, two attributes are extracted and recorded in
a pair, namely ( content,level ). Thecontent describes the
MathML markup of the term and the leveldenotes the level
of the term in the semi-operator tree whose root’s level is 1.
Algorithm 1 To kenizer
1: Letcc(e xp ) be contents of expincluding its descendants
2: Lettag(exp) be the tag of expnode itself
3: Lettext(exp) be the text inside the tag of expnode
4:procedure Tokenize (exp,lev)
5:ifexpis not a leaf then
6: termset←(cc(e xp),lev)⊲ original term
7: genstr←tag(e xp)
8: foreach child ciofexpdo
9: Inserttag(ci) as child of genstr
10
: Tokenize (ci,lev+1)
11: end for
12: termset←(genstr,lev)⊲ g eneralized term
13:else iflength of text(exp)>1then
14: termset←(cc(e xp),lev)⊲ original term
15:end if
16:end procedure
Table 2 illustrates eight terms extracted from ( x+y)×a
b.
Th
e level(L), original and generalized terms are described in
the ﬁrst three columns. For limited space, only the contents
of the generalized terms are given in the last column.
Table 2: Terms of (x+y)×a
b
LOriginal Generalized Generalized (contents)
1(x+y)×a
b(∗)×∗
∗<mo o=’&times;’ >
<m
fenced> </mfenced >
<mfrac> </mfrac> </mo>
2(x+y) (∗) <mfenced > <mrow>
</mrow> </mfenced >
2a
b∗
∗<mfrac> <mi> </mi>
<mi> </mi> </mfrac>
3x+y∗+∗ <mo o=’+’ > <mi> </mi>
<mi> </mi> </mo>
3.6 Indexer
3.
6.1 Problem Analysis
In order to return a list of ranked documents containing
the relevant formulae, the relevance between the query
formula and the document should be calculated. The
existing mathematics retrieval methods mainly focus on how
to calculate therelevancebetweenformulae. Theycannotbe
directly applied to calculate the relevance between a formula
and a document because the formulae and the documents
are in many-to-many correspondences. A document may
contain many formulae and one formula may appear in
many diﬀerent documents. To our best knowledge, how to
calculate the relevance of a query formula and a document
is rarely investigated in the previous studies. Some methods
[11] simply combine the formula relevance score with the
text relevance score without considering the combination of
the scores of multiple relevant formulae in the document.
702Table 3: Index of Terms and Formulae
Terms Inverted index ﬁle
t1
iﬀ(t1)f1[tff(t1, f 1),tl(t1,f1)]→f5[tff(t1,f5),tl(t1,f5)]→
...→fj[tff(t1,fj),tl(t1,fj)]
... ...
ti
iﬀ(ti)f3[tff(ti, f 3),tl(ti,f3)]→f6[tff(t1,f6),tl(t1,f6)]→
...→fk[tff(ti,fk),tl(ti,fk)]
In this paper, we propose a more sophisticated indexing
me
thod to characterize the relevance of the document
containing a numberofrelevantformulae. Astraightforward
way is to select the most relevant formula as the
representative of the document and rank the documents
according to their representatives [4]. However, this method
ignores the relevances of the formulae in the document
other than the selected representative, highly depends on
the accuracy of the similarity calculation between the query
formula and representative formula, and might miss the
documents containing a lot of other relevant formulae.
Another way is to calculate a relevance score between query
formula and the document according to all the formulae
in this document. In other words, we take all the terms
of the query formula and all the terms extracted from all
formulae in this document to calculate an overall relevance
score between the formula and the document. This method
combines all the relevance scores of the relevant terms
appearing in diﬀerent formulae in the document, and might
overate the documents which are not really relevant. We
ﬁnd those two strategies are contrary and complementary
to each other. In order to construct a reasonable strategy, a
hybrid score based on those two strategies is proposed.
3.6.2 Index Method
In order to support eﬃcient online query, we calculate the
statistics of each term oﬄine and store them in the inverted
index ﬁles. Two index ﬁles are built to calculate a hybrid
similarity score of a query and a document: 1) Index ﬁle
for terms and formulae is built to calculate the independent
score, which denotes the similarity between the query and
a single formula; 2) Index ﬁle for terms and documents
is built to compute composite score , which describes the
similarity between the query and all the relevant formulae
in a document.
Index of terms and formulae : To calculate
independent score , an index ﬁle (See Table 3) of terms
and formulae is constructed and this ﬁle is referred to as
index tfhereafter. For each term, a list of formulae, which
contain this term, is recorded. A formula( f) “contains” a
term(t) denotes that the content ﬁeld of one of the terms
extracted from fis exactly the same with that of t. For
each term, iﬀ(ti) describes the inverted formula frequency
ofti:iﬀ(ti) = 1+logNumber offormulae
1+Number o fformulae containing t i.
For each pair of term tiappears in formula fj:tlf(ti,fj)
denotes the level of tiinfj. Since there may be several
occurrences of tiinfjand their levels may be diﬀerent,
tlf(ti,fj) records all the unique levels of tiinfj.tff(ti,fj)
describes the frequency of tioccurring in fj:tff(ti,fj) =
Number oftiin fj
Number oft erms in f j.
It is worth mentioning that, original terms and
generalizedterms ,whichareextractedbythetokenizer(see
Section 3.5), are stored in the same index ﬁle. They can be
discriminated by matching the contentﬁeld of terms, whichTable 4: Index of Terms and Documents
Terms Inverted index ﬁle
t1
id
f(t1)d1[tfd(t1, d 1),tl(t1,d1)]→d2[tfd(t1,d2),tl(t1,d2)]→
...→dj[tfd(t1,dj),tl(t1,dj)]
... ...
ti
id
f(ti)d3[tfd(ti, d 3),tl(ti,d3)]→d5[tfd(t1,d5),tl(t1,d5)]→
...→dk[tfd(ti,dk),tl(ti,dk)]
are generated from a query, because ge neralized terms can
only be matched by generalized terms of the query.
Index of terms and documents : To calculate the
composite score , the index ﬁle (See Table 4) of terms and
documents is constructed and this index ﬁle is referred to
asindex tdhereafter. For each term ti,idf(ti) describes
the inverted document frequency of ti:idf(ti) = 1 +
logNumber ofdocument
1+Number o fdocument containing t i. For each pair of term
tiappears in document dj,tld(ti,dj) records all unique
levels of tiappearing in diﬀerent formulae in document
djandtfd(ti,dj) describes the frequency of tioccurring in
document dj:tfd(ti,dj) =Number oftiin dj
Number oft erms in d j.
3.7 Ranker
When a user searches a formula, the system will
ﬁrstly convert the query into Presentation MathML. Next,
semi-operator tree of the query is obtained by tree
constructor, and then it is tokenized into original terms
andgeneralized terms . After the terms are generated, the
inverted index ﬁles will be looked up and all the matched
terms will be returned to calculate similarity in ranker. The
similarity score between a query Qand a document Dis
deﬁned in Equation 1,
sim(Q,D) =α∗simidp(Q,D)+(1−α)∗simcmp(Q,D),(1)
wheresim(Q,D)isaweightedsumoftheindependentscore,
simidp, and the composite score, simcmp. The independent
score,simidp, denotes the similarity score between the query
and the most similar formula in the document. For a
document, the formula with the highest similarity score
with the query is selected and its similarity score is taken
as the independent score, simidp, between the query and
the document. The composite score, simcmp, describes
the similarity score between the query and all the relevant
formulae in the document. αand 1−αdenote the weights
for the independent score and the composite score. In our
experiment, αis set as 0 .7. Deﬁnitionsof simidpandsimcmp
are given in Equation 2 and Equation 4, respectively.
A document may contain many relevant formulae and
theformula similarity score between the query, Q, and
each formula in the document, Fi, can be calculated. The
simidp(Q,D) chooses theformula with thehighest similarity
score as its document similarity score:
simidp(Q,D) = max
i{Wcover(Q,Fi)∗/summationdisplay
t∈Q(tff(t,Fi)∗iﬀ2(t)∗
Wlevel(t,Q,F i)∗Wgen(t))}.(2)
Theformula similarity score between a formula Fiand
a query Qis the weighted sum of similarity scores of all
matchedterms. For each term tgenerated from thequery Q,
a similarity score is calculated in Equation 2, where tff(t,F)
andiﬀ(t) are stored in the index ﬁle, index tf.Wco ver(Q,F)
denotes the ratio of number of terms in Qmatched by F
to the total number of terms in Q. The term level weight,
703Wlevel, is introduced to evaluate the distance of the matched
terms on diﬀerent levels:
Wlevel(t,Q,F) =1
1+min
j{|l evel (t,Q)−levelj(t,F)|}.(3)
There may be several occurrences of the term tin the
formulaFand they may be at diﬀerent levels of the formula
F. Therefore, diﬀerent level distances may be obtained
through calculating distances between the query term level
(level(t,Q)) and each matched term level ( levelj(t,F)).
In our system, a minimum level distance is taken as the
level distance between the query term tand the formula
F. In order to ensure that the exactly matched terms
would always get higher similarity score than those who
are approximately matched, the weight of generalization,
Wgen(t), is introduced as a penalty of the generalized terms.
Wgen(t) is assigned as 1 if tis an ordinary term, otherwise
Wgen(t) is set as θ, where 0 < θ <1. In our experiment,
θ= 0.5. For instance, calculation of the independent score,
simidp, between formula, ( x+y), and query, ( x+y)×a
b, is
illustrated in Table 5.
Table 5: Independent Score of (x+y)×a
band(x+y)
Matched terms Lq1Lftf*iﬀ2*Wle vel*Wgen
(x+y) 121
4∗8.482∗1
1+|2−1|∗1 =8.99
(∗) 121
4∗2.812∗1
1+|2−1|∗0.5 =0.49
x+y 231
4∗7.712∗1
1+|3−2|∗1 =7.43
∗+∗ 231
4∗4.732∗1
1+|3−2|∗0.5 =1.40
simidp=4
8∗(8.99 +0.49 +7.43+1.40) = 9.16
1Lq&Lfdenote the term level in the query and the formula.
Diﬀerent from independent score, the composite score
scorecmpcalculates thesimilarity of a queryanda document
based upon all the matched terms in a document and it is
as deﬁned in Equation 4,
simcmp(Q,D) =Wcover(Q,D)∗/summationdisplay
t∈Q(tfd(t,D)∗idf2(t)∗
Wlevel(t,Q,D)∗Wgen(t)).(4)
simcmpcombines the similarity scores of all the matched
terms in the document. For each term tgenerated from
the query Q, the similarity score is calculated according
to the term frequency in document, tfd(t,D), and its
inverted document frequency, idf(t).Wlevel(t,Q,D) is
similar with Wlevel(t,Q,F i), but it chooses the shortest
term level distance from a document rather than a formula.
Wcover(Q,D) is similar with Wcover(Q,F), but it indicates
the ratio of terms in Q, which are matched by a document
rather than a formula.
4. EXPERIMENTAL RESULTS
4.1 Dataset
The dataset used in this paper is collected from publicly
available webpages and PDF documents. Therefore,
comparative evaluation with further methods can be carried
out via using the same dataset. Part of the dataset
is collected from Wikipedia, whose copy can be freely
downloaded. Concretely, the 2013-07-08 dump, whose size
is 41 GB uncompressed, is used. This dataset contains
13.6 millions webpages and 521,782 mathematical formulae.The other part is collected from a publicly available PDF
document set proposed for formula identiﬁcation [6]. It
contains 400 pages from 194 documents, which are crawled
from CiteSeerX. The dataset consists 9,482 formulae. Since
the precise boundaries of all the formulae are already
provided in this dataset, their Presentation MathML
markups are obtained based upon the given boundaries, via
adopting formula structure analysis [17] with modiﬁcation
and manual correction.
4.2 Time & Space Efﬁciency
The index ﬁles are constructed oﬄine on a MacBook Pro
with 2.8 GHz Intel Core i7, 4 GB DDR3 and 750 GB SATA
Disk. The system is implemented using Scala based on
Lucene. The time taken to construct the index ﬁles and the
sizes of the index ﬁles are evaluated with increasing amount
of indexed formulae, as shown in Table 6. It costs less than
40 minutes to generate two index ﬁles after the dataset is
inputted to our system. The total size of index is less than
1.2 GB. As the number of indexed formulae increases, the
construction time and sizes of index ﬁles increase steadily.
Table 6: Construction Time and Sizes of Index Files
Number of formulae 1,036 10,096 100,048 531,264
Time (MM:SS) 00:16 00:29 03:47 37:10
Size ofindextf(MB)0.72 7.0 65 291
Size ofindextd(MB)0.67 6.3 65 856
Total size (MB) 1.39 13.3 130 1,147
Table 7 illustrates the query time with increasing amount
of
indexed formulae. The minimum, maximum, median and
average querytime over100 diﬀerentqueries are testedupon
indexes based on increasing number of indexed formulae. It
is seen that as the size of index ﬁle increases, the average
query response time increases steadily. On average, it costs
around 500ms to respond to a query. The maximum query
time is cost by the queries containing many commonly seen
terms (e.g., x2), because the more number of formulae
or documents contain the queried terms, more time is
consumed to merge the document lists.
Table 7: Query Response Time
Number of formulae 1,036 10,096 100,048 531,264
Min (ms) 8 10 13 28
Max (ms) 147 431 532 1,419
Median (ms) 14.0 21.5 111.5 488.5
Average (ms) 18.3 29.8 114.6 514.1
4.3 Accuracy
4.
3.1 Compared Algorithms
We compare the proposed method with two baseline tree-
based indexing mathematics retrieval systems: 1) MIaS
[15] indexes all the substructures of formulae and calculates
the similarity of each substructure considering their levels.
Because the MIaS is built upon arXiv dataset rather than
Wikipedia, we re-implement this method to compare in
this paper. 2) WikiMirs [2] is a representative tree-based
indexing system without semantic enrichment based on
Wikipedia. It indexes all substructures of the formulae in
LATEX considering the generalization of substructures.
In order to verify the eﬀectiveness of the proposed
techniques (semantic enrichment in tree constructor,
normalization and generalization in tokenizer), comparison
704is also carried out when these techniques are turned oﬀ
se
lectively. Concretely, four systems are constructed with
four diﬀerent conﬁgurations: 1) oursbase: Neither semantic
enrichment nor normalization or generalization are adopted
and this is considered as a baseline method; 2) oursgen:
Semantic enrichment and normalization of operand order
are turned oﬀ, but generalization is adopted; 3) ourssem:
Semantic enrichment and normalization of operand order
are adopted, but generalization is turned oﬀ; 4) Ours: The
proposed system with all theproposed techniquesturnedon.
4.3.2 Query Set
In this paper, a queryset containing 100 queries is utilized
for evaluation. Among this query set, 70 queries with one
relevant page for each queries are provided by [4]. 12 queries
are the queries used in the literatures [2] and [13]. The
rest is newly added and they are collected from formulae
in Wikipedia. In order to facilitate further comparison, the
query set, along with the scores for corresponding retrieved
documents given by the subjects, are publicly available at
our system’s address.
4.3.3 Evaluation Measures
For each test query, the top- kdocuments retrieved by the
six diﬀerent systems are evaluated. The relevances between
the retrieved documents and the queries are judged by ﬁve
postgraduates majoring in Computer Science. The query
set is divided into ﬁve independant parts randomly and
equivalently. Andeach part, containing 20 queries, is judged
by a subject. For each query, top- kresults returned by each
system are presented to the subject in order. Each result
(document), includes the title, URL, and a representative
formula, which achieves the highest simidpscore. For each
result, a subject gives a relevance score, where score∈
{0,1,2,3,4,5}. 0 denotes the no score has been assigned
yet, 1 indicates the result is irrelevant, and 2 ∼5 denotes
the relevance between the result of the query, where higher
scoreindicates higher relevance.
To increase the eﬃciency of manual measurement and
insure the same result gets the same judge in diﬀerent
systems, a judging interface is implemented to reuse the
labeled resultsvia recordinga mapfrom ( Q,D) toitslabeled
score. In other words, if a speciﬁc ( Q,D) has been judged
in a system, the subjects do not need to judge it again when
scoring other systems. The labeled results of each system
for all the queries are released along with the query set.
Average Precision (P) andDiscounted Cumulative Gain
(DCG) [3] are calculated based on the top- kretrieved
documents over all queries. For each query, a list of scores
of the top- kresults is given by the subjects. The i-th
element scoreiin the score list denotes the score of the i-th
retrieved document. Pis calculated based on whether the
retrieved document is relevant ( scorei>1) to the query or
not (scorei= 1).Pof the top- kresults is calculated as,
Pk=/summationtextk
i=1Number ofrelevant documents
k.DCGis calculated
based on the relevant score of the result according to its
positionintheresultlist. DCGofthetop- kresultsisdeﬁned
as,DCGk=/summationtextk
i=12(scorei−1)−1
log2(i+1).
4
.3.4 Performance of the Top- kResults
The average PandDCGat top-kresults over all queries
are illustrated in Table 8. From the experiments, we ﬁnd
that WikiMirs usually retrieves a small number of resultsand most of them are relevant. MIaS retrieves much more
results, but it does not rank the relevant results properly.
This is mainlywhyMIaSachieves higher P10thanWikiMirs,
while has a lower DCG10than WikiMirs. It should be
mentioned that MIaS is proposed towards arXiv and the
parameters and settings are tuned for this dataset. We
consider this might be an important factor aﬀecting MIaS’s
performance here. For WikiMirs, it is found that no result
is returned for about 40 queries and it is considered as the
main reason why WikiMirs achieves lower PandDCG.
By comparison, the proposed method achieves a
signiﬁcant improvementin PandDCG. Compared with the
baseline strategy ( oursbase), both generalization strategy
(oursgen) and semantic enrichment with normalization
strategy ( ourssem) achieves higher P10andDCG. It is seen
that through adopting these strategies, the relevant results,
which do not exactly match the query but share similar
structures with diﬀerent presentations, are retrieved back
and ranked properly. The proposed system, using all these
techniques, makes a distinct improvement in PandDCG,
compared with the other methods.
Table 8: Average Precision & DCG at Top- kResults
Systems P3P5P10DCG3DCG5DCG10
MIaS 0.350.350.34 1.96 2.56 3.75
WikiMirs 0.400.380.31 5.34 6.43 7.95
oursba se0.820.800.7211.70 14.31 18.10
oursge n0.820.800.7512.23 15.22 19.57
oursse m0.820.810.7412.96 16.23 20.54
Ours 0.860.840.7914.47 17.90 23.27
4.3.5 Case Study
Fo
r each document, the formula with the highest
formula-query score is selected to be the representative
of this document. Table 9 shows two queries with top-5
results retrieved by diﬀerent systems, ordered by document
similarity scores with the query.
Take/summationtext∞
n=0(−1)nx2n
(2n)!asanexample, thesametop-2results
containing exact content of the query are found by both
WikiMirs and our system. However, the top-3 result of
our system is obviously more relevant to the query, since
it shares more common substructures with the query. It
is mainly because more delicate substructure matching and
similarity calculation is adopted in our paper.
Takef(x) =/parenleftbig1
x+1/parenrightbigxas an example, no result is
returned by WikiMirs because the operand order of “+”
in query is diﬀerent from those in document set. Only
one result is returned by WikiMirs even if the order of
the operand “+” is the same with those in document set.
Reasonable results are returned by our system in either
cases. It is mainly because semantic enrichment is adopted,
so that the substructure of/parenleftbig1
x+1/parenrightbigxcan be extracted,
hierarchicalgeneralization enablesequationscontainingsuch
substructure rank higher, normalization of operand order
overcome the diﬀerent presentations of1
x+1and 1+1
x.
5.
CONCLUSIONS
To facilitate the access and search for mathematical for-
mulae in existing information systems, this paper investi-
gates the main challenges in constructing mathematics re-
trieval system for formulae in layout presentations. Mean-
while, a mathematics retrieval system focusing on such for-
mulae is proposed, with the following three contributions:
705Table 9: Comparison of Top- 5Re sults of Diﬀerent Systems
Queries Systems Top-5 results
/summationtext∞
n=0(−1)nx2n
(2n)!
(
substructure/fuzzy
match)MIaS 2n;n(n−1) ; 2n−1;n;e=/summationtext∞
n=01
n!
WikiMirs cosx=/summationtext∞
n=0(−1)nx2n
(2n)!;cosx=/summationtext∞
n=0(−1)nx2n
(2n)!;(2n)!;/summationtext∞
n=0/bardblfn/bardbl:=
/summationtext∞
n=0supS|fn(x)|<∞.cosx= 1−x2
2!+x4
4!−x6
6!+···=/summationtext∞
n=0(−1)nx2n
(2n)!
Ours cosx=/summationtext∞
n=0(−1)nx2n
(2n)!;cosx=/summationtext∞
n=0(−1)nx2n
(2n)!;coshx=/summationtext∞
n=0x2n
(2n)!;/summationtext∞
n= 0(−1)nz2n.;
(2n)!
n!
f(x) =/parenleftbig1
x+1/parenrightbigx
(
generalization,
substructure match)MIaS a=f(x); +; +; n= 1+D/2;z=a+ib
WikiMirs No result. f(x) =/parenleftbig
1 +1
x/parenrightbigxisreturned when searching f(x) =/parenleftbig
1+1
x/parenrightbigx.
Ours f(x) =/parenleftbig
1 +1
x/parenrightbigx;/parenleftbig
1+1
x/parenrightbigx;e= limx→∞(1+1
x)x; limx→∞/parenleftbig
1+1
x/parenrightbigx=e; limx→∞/parenleftbig
1+1
x/parenrightbigx
1) This system supports searching formulae from both web-
pa
ges and PDF documents with a novel query input inter-
face, which enables users to input query formula directly
when reading PDF documents. 2) A semantic enrichment
technique is proposed to extract useful semantic informa-
tion from formulae in layout presentation, resulting in bet-
ter support for reasonable normalization of operand orders
and generalization of substructures. 3) Hierarchical general-
ization of substructures is proposed to generate index terms
to support substructure matching and fuzzy matching. 4)
The problem of scoring a document with multiple relevant
formulae is addressed, and a hybrid scoring method, consid-
ering both the most relevant formula and multiple relevant
formulae, is proposed. Experiments for self-comparison are
carried out to prove that the aforementioned techniques do
help to improve the performance of mathematics retrieval.
Moreover, comparison experiments with two representative
systems also show that the proposed system achieves better
performance.
The proposed system, dataset and query set are publicly
available for further comparison. Meanwhile, we plan
to re-evaluate and reﬁne our system via participating in
competition of NTCIR Task Math8, which provides a test
collection and a set of tasks for mathematics retrieval.
6. ACKNOWLEDGMENTS
This work is supported by the National Natural Science
Foundation of China (No.61202232).
7. REFERENCES
[1] A. Aula and M. K ¨aki. Understanding expert search
strategies for designing user-friendly search interfaces.
InICWI, pages 759–762, 2003.
[2] X. Hu, L. Gao, X. Lin, Z. Tang, X. Lin, and J. B.
Baker. Wikimirs: a mathematical information retrieval
system for wikipedia. In The 13th ACM/IEEE-CS
joint conf. on Digital libraries , pages 11–20, 2013.
[3] K. J¨arvelin and J. Kek ¨al¨ainen. Ir evaluation methods
for retrieving highly relevant documents. In The 23rd
Int. ACM SIGIR Conf. , pages 41–48. ACM, 2000.
[4] S. Kamali and F. W. Tompa. Retrieving documents
with mathematical content. In The 36th Int. ACM
SIGIR Conf. , pages 353–362. ACM, 2013.
[5] M. Kohlhase and I. Sucan. A search engine for
mathematical formulae. In Artiﬁcial Intelligence and
Symbolic Computation , pages 241–253. Springer, 2006.
8http://ntcir-math.nii.ac.jp/[6] X. Lin, L. Gao, Z. Tang, J. Baker, and V. Sorge.
Mathematical formula identiﬁcation and performance
evaluation in pdf documents. Int. J. Doc. Anal.
Recogn. (IJDAR) , 2013.
[7] M. L´ ıˇ ska, P. Sojka, and M. Ruˇ zicka. Similarity search
for mathematics: Masaryk university team at the
ntcir-10 math task. In Proc. of the 10th NTCIR
Conference , pages 686 – 691, 2013.
[8] X. Liu. Generating metadata for cyberlearning
resources through information retrieval and
meta-search. JASIST, 64(4):771–786, 2013.
[9] B. Miller and A. Youssef. Technical aspects of the
digital library of mathematical functions. Annals of
Mathematics and Artiﬁcial Intelligence, 2003.
[10] R. Miner and R. Munavalli. An approach to
mathematical search through query formulation and
data normalization. Towards Mechanized
Mathematical Assistants , pages 342–355, 2007.
[11] J. Miˇ sutka and L. Galamboˇ s. Extending full text
search engine for mathematical content. Towards
Digital Mathematics Library, pages 55–67, 2008.
[12] T. T. Nguyen, K. Chang, and S. C. Hui. A math-aware
search engine for math question answering system. In
The 21st ACM Int. Conf. on Information and
Knowledge Management , pages 724–733. ACM, 2012.
[13] T. T. Nguyen, S. C. Hui, and K. Chang. A
lattice-based approach for mathematical search using
formal concept analysis. Expert Systems with
Applications , 39(5):5820–5828, 2012.
[14] T. Schellenberg, B. Yuan, and R. Zanibbi.
Layout-based substitution tree indexing and retrieval
for mathematical expressions. In IS&T/SPIE
Electronic Imaging , volume 8297, page 82970I, 2012.
[15] P. Sojka and M. L´ ıˇ ska. Indexing and searching
mathematics in digital libraries. Intelligent Computer
Mathematics , pages 228–243, 2011.
[16] R. Zanibbi and D. Blostein. Recognition and retrieval
of mathematical expressions. Int. J. Doc. Anal.
Recogn. (IJDAR) , pages 1–27, 2012.
[17] R. Zanibbi, D. Blostein, and J. R. Cordy. Recognizing
mathematical expressions using tree transformation.
IEEE Trans. on Pattern Analysis and Machine
Intelligence , 24(11):1455–1467, 2002.
[18] J. Zhao, M.-Y. Kan, and Y. L. Theng. Math
information retrieval: user requirements and prototype
implementation. In The 8th ACM/IEEE-CS joint
conf. on Digital libraries , pages 187–196. ACM, 2008.
706