Music Retrieval from Everything
[Extended Abstract]
Tristan Jehan
The Echo Nest Corporation
48 Grove Street, Suite 206
Somerville, MA 02144
tristan@echonest.comPaul Lamere
The Echo Nest Corporation
48 Grove Street, Suite 206
Somerville, MA 02144
paul@echonest.comBrian Whitman
The Echo Nest Corporation
48 Grove Street, Suite 206
Somerville, MA 02144
brian@echonest.com
ABSTRACT
The Echo Nest Corporation, a music intelligence platform
company based on years of music retrieval research and de-velopment, provides a number of retrieval, search and in-
teractivity tools to music stores, social networks, musicians,
developers and labels around the world. Our platform
1con-
sists of a series of heterogeneous data types: text data from
web crawls, audio signal processing and machine learning,
natural language processing, graph manipulation and large
scale map-reduce style data aggregation and sorting.
Categories and Subject Descriptors
H.4 [Information Systems Applications ]: Miscellaneous;
D.2.8 [ Software Engineering ]
General Terms
Algorithms, Design, Measurement
1. ARTIST SIMILARITY USING FREE TEXT
Data mining approaches to music retrieval [1] inspired
much of the research that went into the Echo Nest's cur-
rent artist-level \cultural" similarity computations. In an
early paper [4] pure-text approaches to artist similarity are
introduced, using simple tagging and chunking algorithmswith gaussian weighted term counting to associate \salientterms" to artists. Artist distance can be computed by term
overlap and can be evaluated by matching against user feed-
back or edited similarity measures. This work was improvedupon to use audio features to guide term selection in an
\auto-tagging" framework [5] [3].
2. SONG SIMILARITY USING CULTURAL
AND ACOUSTIC DATA
Per-song similarity at a scalable level has eluded auto-
mated systems as acoustic-only metrics of audio similarity
tend to return terrible results to human judges. The dis-
connect between distance metrics on perceptually derived
data and cultural factors around the music (christian rockvs. hard rock; new age vs. electronic music; hard bop vs.smooth jazz, etc) cause intense listener displeasure. At the
1http://developer.echonest.com/
Copyright is held by the author/owner(s).
MIR’10, March 29–31, 2010, Philadelphia, Pennsylvania, USA.     
ACM 978-1-60558-815-5/10/03.Echo Nest we have built a hybrid model of song similarity
that fuses our cultural results based on free text analysiswith acoustic level features. We use the cultural results at
the artist level as sort of a \pre-lter" to narrow the search
space for acoustic similarity, which is based on segment-levelchroma and timbre analysis [2].
3. PLAYLIST GENERATION USING GRAPHS
Connections between artists and songs are used in valu-
able ways in our playlist generation products. We build a
directed graph where the nodes in the graph are the artists
and the edges represent similarity and can use a Dijkstra
shortest-path algorithm to nd the shortest path betweentwo artists. We can dynamically adjust the weights on theedges to eect the shortest path based on user constraints
(desired artist familiarity, exclude lists). For instance, we
can create a playlist through the most popular artists byre-weighting the edges so that edges to artists with a highfamiliarity have lowest cost.
4. ANALYTICS AND POPULARITY
A large portion of our data centers around usage patterns
of listeners. We currently track tens of millions of music lis-
teners across multiple web properties, either through client
deals or web crawling. The analytic data collected is used
to inform our notions of \familiarity" (the probability that amusic fan will have heard of an artist) and \hotttnesss" (thedaily measure of how talked about or listened to an artist
is.)
5. REFERENCES
[1] W. W. Cohen and W. Fan. Web-collaborative ltering:
recommending music by crawling the web. WWW9 /
Computer Networks , 33(1-6):685{698, 2000.
[2] T. Jehan. Creating music by listening . PhD thesis,
Massachusetts Institute of Technology, 2005.
[3] B. Whitman. Learning the meaning of music . PhD
thesis, Massachusetts Institute of Technology, 2005.
[4] B. Whitman and S. Lawrence. Inferring descriptions
and similarity for music from community metadata. In
Proc. Int. Computer Music Conference 2002 (ICMC) ,
pages 591{598, September 2002.
[5] B. Whitman and R. Rifkin. Musical
query-by-description as a multi-class learning problem.InProc. IEEE Multimedia Signal Processing
Conference (MMSP) , December 2002.
245