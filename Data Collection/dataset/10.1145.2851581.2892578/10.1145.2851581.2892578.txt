Does Technology Have Race?
Abstract 
This paper started as a response to the “Black Lives 
Matter” campaign in the United States, and emerged as a critique of race more generally in technology design. This paper provides case studies of how technologies are often less usable by persons of color, and contextualizes this in light of intersectionalist theory. Finally, it discusses how the HCI community can ameliorate the situation, and our obligation to do so in light of the ACM code of ethics. 
Author Keywords 
Race; Social Justice; Computing; Racism 
ACM Classification Keywords 
• Human-centered computing~Human computerinteraction (HCI) • Social and professional topics~Raceand ethnicity.
Introduction 
Stephen Colbert is noted for the catch phrase, “I don’t see race” [33]. It is part of a Liberal ideology that hopes by being blind to race you can achieve blind justice. Of course, in doing so it fails to note the cultural contributions that stem from that difference. Further, one cannot simply close ones eyes and avoid the effects of pre-existing bias. The term bias is used by Friedman and Nissenbaum, who say it “refers to computer systems that systematically and unfairly Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are  
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
 
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org.  CHI'16 Extended Abstracts, May 07-12, 2016, San Jose, CA, USA.  
© 2016 ACM. ISBN 978-1-4503-4082-3/16/05...$15.00. DOI: http://dx.doi.org/10.1145/2851581.2892578  David Hankerson 
Andrea R. Marshall Jennifer Booker Houda Elmimouni Imani Walker 
*Jennifer A. Rode
Rainbow LaboratoryDrexel University, USAdjh343@drexel.eduandrea.marshall@drexel.edugbooker@drexel.eduhe52@drexel.eduiw48@drexel.edu
jen@acm.org
*Contact Author
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
473
Most up-to-date version: 02/15/2023discriminate s against certain indivi duals or groups of 
individuals in favor of others .” [10, p23]. By extension 
pre-existing societal bias is “bias that originates from 
society at large, such as from organizations (e.g., industry), institutions (e.g., legal systems), or culture at large. (E.g., gender biases present in the larger society that lead to the development of educational software that overall appeals more to boys than girls)” 
[10, p24]. Pre-existing bias can be implicit and subconscious, rather than malicious in intent. Yet, this sort of bias still has negative effects by failing to provide appropriate technologies for underrepresented minorities in STEM, and as such in this paper we will argue for the existence of pre-existing social biases regarding race in HCI, provide examples of interfaces that challenge minority users, and discuss possible 
ways to ameliorate future designs and design cultures. 
Literature Review A search for the term ‘race’ in the ACM digital library (excluding the phrase ‘rac e conditions’) yields 897 
results, where a search for the term ‘racism’ yields only six. The term racism implies not just neutrally categorizing data based on race, but rather a political motivation and acknowledgement of pre-existing social bias. The bulk of work on race focuses on the disparities of participation of minorities in computing without a specific political agenda. The discussion of racism include an article on addressing values in design 
including racism [20], one on critical game play [13] one on classifying racist texts [14], one on cyber-bullying in information retrieval [25], an article on the Twitter response to the decision as to whether to indicate the white police officer responsible for Eric Garner’s death, and a poem [9]. This is hardly a research showing that is consistent with the impact of discussions of racism in the popular press. Consider the Black Lives Matter movement, and that in 2015 African American were disproportionately likely to be shot by police [45]. African American men represent 6% of the US population but represente d 40% of those killed by 
police. If racism is such a significant topic in the United 
States, regardless of its applicability to CHI worldwide, why is it not reflected in our literature? 
Elsewhere in the CHI literature Rode has argued the 
HCI community has wanted to treat technology as value neutral [30], and yet this is not the case, as 
other scholars in HCI have previously noted in their 
own research. To wit, Winner argued artifacts are actively imbued with the political values political characteristics held by those who construct them [54]. Similarly, Berg and Lie argued artifacts traditionally take on gender characteristics that reflect the values of their creators [5].  Therefore, it is reasonable to assert that similarly to scholarly arguments about the construction of gendered and politicized artifacts, then technologies can have race, and technology creators in turn can perpetuate racial bias. This is not to say that members of the HCI community are intentionally creating racist technology, as pre-existing social bias can be unintentional, one possible source is ‘white privilege’. This is an emotionally laden term as discussed by Hugo award winner science fiction author John Scalzi, as he tries to explain the concept to fellow gamers at the height of Gamergate, 
“I've been thinking of a way to explain to straight 
white men how life works for them, without invoking the dreaded word "privilege," to which they react like vampires being fed a garlic tart at high…. 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
474“Dudes.  Imagine life here in the US - or indeed, 
pretty much anywhere in the Western world - is a 
massive role playing game, like World of Warcraft except appallingly mundane, where most quests involve the acquisition of money, cell phones and donuts, although not always at the same time. Let's call it The Real World. You have installed The Real World on your computer and are about to start playing, but first you go to the settings tab to bind your keys, fiddle with your defaults, and choose the difficulty setting for the game. Got it?” 
“Okay: In the role playing game known as The Real 
World, "Straight White Male
1" is the lowest difficulty 
setting there is.” 
“This means that the default behaviors for almost all 
the non-player characters in the game are easier on you than they would be otherwise. The default barriers for completions of quests are lower. Your leveling-up thresholds come more quickly. You automatically gain entry to some parts of the map that others have to work for. The game is easier to play, automatically, and when you need help, by default it's easier to get.” [37]  
                                                 
1 In this example the trifecta of straight identities, whiteness, 
and maleness are being positioned as equally problematic. The 
sex and gender identity aspects of this example are not important to this analysis—though extremely important elsewhere. Here we merely want to emphasize ‘whiteness’ is in Scalzi’s words “an easier difficulty setting” than engaging with the world as a user of color, and are using this sort of gamer 
metaphor as a design fiction. 
Also we are using the terminology Black and White as 
Americans, as that is the word choice within the “Black Lives 
Matter” Community. We recognize elsewhere, like the UK, it has a different political tone [27]. While perhaps not the most sch olarly explanation of the 
theory it is certainly an approachable metaphor, life is 
just a bit easier if one is Caucasian because the society is a bit more supportive and suited to one’s needs. Technology like any aspect of society is just a bit easier to use if one happens to be Caucasian.  
Our feminist intersectionalist frame also calls white 
women’s responsibilities into question. (Perhaps, this is especially ironic as three of the supporting authors of the paper are white (queer) women. The fourth author is an Arab Muslim woman.) This accountability of white women is something feminists of color have indicated is an ongoing rift within discussions of intersectionalism [16, 47, 55]. The interlocut ion between HCI literature 
and intersectionalist perspectives is an emergent one; it is one that, such as Trauth  et al. argue, “Rather than 
examining identity characteristics such as race, ethnicity, gender and class in isolation, intersectionality considers how these interact to mutually construct one another” [52, p.199]. We hope to expand this discussion with ways to further our understandings of how multifaceted user identities and perspectives can be critically understood in order to expand diversity within computing cultures and how it may be sustainable in terms of practitioners [7, 11, 53]. Young’s [59] form of intersectionality, the Lived Body Experience is perhaps most known to the HCI community in that it addresses a person’s embodied interaction with the world through the intersectional lenses of their race, gender, sex, (dis)ability, age, etc. 
Similarly, Sun’s work culturally responsive computing [48, 49] and Kafai’s research on ethnocomputing [18] 
both build on intersectionality and are known to CHI.  
Here we hope to provide case studies to contextualize 
this discussion and draw much needed attention to it. 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
475We will then discuss the range of tools (user research, 
usability testing, value sensitive design) which the HCI community can use to minimize preexisting bias and white privilege in HCI. Up to this point we discussed race theoretically, but next we will provide a survey of examples where technology use is easier for Caucasians than underrepresented minorities. 
Examples of Technologies with Racial Bias  
We have cataloged a range of incidents where race has adversely affected technology’s usability for underrepresented minorities. We will discuss three areas where this has occurred—in sensor design, in algorithms and in interface design. 
Sensors Automatic Faucets In 2015 a video went viral on YouTube [27] where a dark-skinned man was not able to use a public sink with an automatic soap dispenser (see Figure 1), but a light-skinned man was. As a result many articles have been written recently publicizing this issue [12, 29, 31]. This clear case of racial bias in everyday technology leads to the questions: how is this possible? And what is being done about it? 
Automatic faucets and soap dispensers typically work 
by sending an infrared beam toward the sink. When a person’s hands enter the beam, some of the beam is reflected back to the sensor, and it knows to allow water or liquid soap to flow. The problem is that darker skin reflects less of the infrared beam than lighter skin, so the sensor can fail to detect the presence of a darker hand. This problem has been known since the early 1990’s [39]. Faucets can be adju sted during installation 
for the range of the beam [2, 43], from typically 2-10 
inches, with a default value of 6 inches, but nowhere do these major brands of faucet allow adjustment of the 
sensor sensitivity for darker skinned users. Consumer literature only shows Caucasian people [44]. In the troubleshooting guide, one faucet maker says if the faucet doesn’t respond to someone within its sensor range, they only suggest the battery may need replacement [34]. Nevertheless, faucets sold in India have been adjusted to work with darker skin tones [30], they made the faucet more responsive to decreased signal reflected from the darker-skinned users. This adjustment could be made easily during installation in response to user demographics elsewhere, yet neither Sloan or American Standard have implemented these solutions. Not only are automatic faucets and soap dispensers, which were intended to improve hygiene [6], of questionable effectiveness at reducing bacteria, and are harder to clean [46], their solvable us ability problem for minority 
users has remained unaddressed for decades [39]. 
Apple iWatch 
Another example of sensor technology failing for dark-skinned people is the pulse monitor function in Apple 
Watches (see Figure 2). A medical pulse 
oximetry (pulseox) meter measures the percent of 
oxygen capacity in blood (which is near 100% for healthy people), however someone figured out how to determine one’s pulse from a slight rise which occurs in pulseox with each heartbeat [41]. Apple has taken a pulseox and removed the oxygen measurement and just used it to measure one’s pulse, e.g. during exercise, and uses beams of green and infrared light which are reflected into photodiode sensors [3]. 
Within days of the release there were reports pulse 
measurement did not work if the subject had some 
shades of red or black tattoo s on their arms. This had a  
Figure 1: Automatic Faucet. 
(Image Credit: Shaun Kane) 
 
Figure 2: Sensors on Apple 
iWatch. The circles in the 3 and 9 o’clock positions are green and 
infrared LEDs. The ones in the 12 
and 6 o’clock positions are photodiode sensors.           
(Image Credit: Shaun Kane) 
 
 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
476secon
Pay bskin, the ware r
e
readin
system
Figure 3. “My frTwitter feed. (I
m
Befor e
skin w
[50] s
light c
so. Ap
has n o
dary effect of ma
ecause it thinks i t
[51]. Apple confi r
atches “Dark ink s
eportedly more pr
ngs, given how c o
m” [3].  
iend’s not a Gorill
mage Credit: Rai n
e long, people re a
were not being ac c
suggests that cha n
could help fix the 
pple acknowledge
ot commented on
king the watch d e
t lost contact with
rmed that tattoos  
s, such as red, bl u
one to obscuring 
olors play into the  
a.” Screenshot o f
nbow Lab)  
alized that some s
curately measure d
nging the sensor s
problem, but Ap p
s the problem wi t
 the racial implic a
eactivate Apple 
 the user’s 
 could confuse 
ue and black, 
heart rate 
 device’s sensor 
 
f Alciné’s public 
shades of darker 
d, and Taylor 
s to use yellow 
ple has not done 
th tattoos, but 
ations. They 
recomme n
more acc u
impractic a
financial b
In both th e
iWatch w e
appropria t
incidents a
disparity, 
to directly  
Algorithm s
“My Frien d
Jacky Alci n
June of 2 0
images of  
“gorilla” ( s
white skin  
ideal stan d
“We’re ap p
[36]. This 
represent a
Google’s c
it is rathe r
more spe c
elaborate d
by some a
will learn f
Neverthel e
overtime, been prev
e
data sets [nd using an exter n
urate pulse readin
al for 24/7 use, a n
burden on minorit y
e case of the aut o
e see examples of  
tely when used b y
a technical soluti o
but in both cases  
y address claims o
s 
d’s Not a Gorilla. ” 
né, a former Goo g
015 in response t o
 black people in t h
see Figure 3). This
 bias that consid e
dard to be pictur e
palled and genui n
 might partially i n
ation of minoritie s
chief architect for  
r due to the way m
cifically the way a
d that, in this cas e
aspect of an imag e
from getting feed b
ess, while the alg o
 we like Alciné ar g
ented by testing w
[22].  nal Bluetooth che s
gs [3], however t
nd places an addi t
y users.  
omatic faucets an
 sensors that do n
y non-White user s
on exists to addre s
 manufacturers h a
of racism. 
 
gle intern, tweete
o Flickr and Googl
heir photo app as  
s fiasco is a remi n
ers light-skin ton e
ed [36]. Google a p
nely sorry  this ha p
ndicate the under -
s in Silicon Valley .
social, Yonatan Z
machines recogni z
lgorithms learn. Z
e, the algorithm w
e’s patterns. The 
back from users.  
orithm may corre
gue the situation c
with more raciall yst strap for 
this is 
tional 
d the Apple 
not function 
s. In both 
ss the 
ave failed 
d to this in 
e labeling  
 “ape” and 
nder of the 
es as the 
pologized, 
ppened 
-
. However, 
unger, said 
ze faces or 
Zunger 
was fooled 
algorithm 
ct itself 
could have 
y diverse 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
477“No, I did not blink... I'm just Asian!” 
Face detection is an intelligent technology that aims at making photography more convenient and ensuring best results. One of its po pular features is autofocus 
where the camera detects the face to define the focus of the photo. In addition, some cameras with a face detection function can warn the photographer when someone in the frame blinks. While tackling face detection two incidents have shown how technology failed to embrace race diversity.  
In the first case, Joz Wang, an Asian American blogger, 
has got her mom a Nikon Coolpix S630 for Mothers’ Day. While taking pictures for the family, the camera kept prompting "Did some one blink?", although 
everybody’s eyes were open. Wang’s camera had 
difficultly detect her and her family’s eyes as open because it “was incapable of  distinguishing her narrow 
eye from a half-closed one. An eye might only be a few pixels wide, and a camera that’s down sampling the images can’t see the necessary level of detail” [33].  
The second case is a viral YouTube video with 3 million 
views casting light on the bias of HP Pavilion laptop cameras towards dark skinned people. In the video, an African American man and his white female co-worker tested the face detection and tracking functions of the built-in webcam on an HP Pavilion laptop. The HP laptop detected the white colleague’s face and followed her as she moves within th e frame, whereas it never 
detected the African American’s face. Finally, when he is in frame it stops detecting both faces. The African American man concludes: “I  welcome responses to why 
the HP webcam does not pick up Negros” [58]. Both Nikon and HP state th ey are working to improve 
their product [33], however both issues demonstrate significant usability gaps for minority users.  
Interface Design 
Video games and race 
Video games have been sparki ng plenty of criticism as 
they are claimed to promote racism and cultivate and 
intensify racist stigmas. They are found to “represent a 
powerful instrument of hegemony, eliciting ideological 
consent through a spectrum of white supremacist 
projects” [22].  Further, one study found over two-
thirds of the main characters were white (68%), 
followed by Latino (15%) and black (8%) [8]. An 
analysis of games by Williams et al [56] found a 
systematic over-representation of males, white and 
adults and a systematic under-representation of 
females, Hispanics, Native Americans, children and the 
elderly. 
For instance, one of the most popular racist video games 
is Resident Evil 5 where a well-muscled white American 
man shoots masses of brainless diseased Africans as 
soon as he gets to see them and even before 
metamorphosing into monsters. Other popular games 
like Uncharted and the God of War all revolve around the 
same story of a strong white man shooting non-whites 
that turn into savages. While there might be very few 
enemies to the game’s hero that are white, they are 
always visibly monstrous. In general, Black personas are 
rarely present as prominent characters. In Final Fantasy 
VII, the only black persona is usually cruel, speaks poor 
English, and follows queer stereotypes. The only 
romantic black character in Mass Effect cheats, makes 
another woman pregnant and his father is a criminal 
[37]. Call of Duty 4 portrays Middle Easterners as brutal 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
478savages all acting irration ally. Almost all Arabs and 
Muslims in games are portrayed as insane lunatics who 
care only about war. In Killzone, the character Rico 
Velasquez is dark skinned but his name is clearly Latino. 
He is depicted as “the most ignorant and foul-mouthed 
character in the Killzone” [16]. With depictions such as 
these we have to agree with Griffith’s study, that video 
games are perpetrating racism [15]. 
Emojis 
The computer-mediated communication (CMC) mode 
imposes conversational constraints on users’ language owing to the lack of the contextual cues that are richly available in the face-to-face communication. Thus, 
emojis and emoticons are often utilized to circumvent 
these limitations. In 2014,  a comic interview with 
Sasheer Zamata [60] on NBC’s Weekend Update 
criticizes the number of emojis representing white 
people, but without a single  one available depicting a 
black person. Sasheer shared her experience using a 
black moon as a representati on of a black skinned face. 
In early 2015, Apple, in conjunction with Unicode 
Consortium, released a new set of emojis that are said to 
be diverse. In the iOS 8.3 update, these emojis allow for 
skin color customization. The new emoji have quickly 
been appropriated, and many have no doubt find them 
liberating, but one problem that has arisen is that they 
are being used to make racist comments on social media, 
and they are also used to insert questions of race in texts 
and tweets, for instance Clorox’s campaign “New Emoji’s 
are alright but where’s the bleach” was critiqued for 
racist undertones [54]. Further, the “Nightly Show with 
Larry Wilmore” discussed how people have found 
themselves compelled to identify themselves with a 
matching emoji skin color as using another emoji color can be insulting [40]. In the literature, emoticons are 
found to have multiple key functions; they regulate the 
interaction, disambiguate the message, express affect, 
strengthen a message, and convey humor, mitigate or 
aggravate disagreement and influence negative feedback 
acceptance. Above all, they contribute to enable 
receivers to correctly understand the level and direction 
of emotion, attitude, and attention expression [24]. Thus 
emoticons are contextually situated and therefore, the 
interpretation of an emoticon depends on their contexts. 
To our knowledge, no research indicated a necessity for 
emojis to represent race or skin color. There is little 
known about the process the Un icode consortium used to 
debate the inclusion of the new icons, nor whether 
representatives of the minority communities (e.g. 
NAACP) were contacted. Yet, we see how these icons 
have been appropriated to be explicitly racist [54]. Given 
the social impact it is clear such decisions need to be 
made with greater care. 
Black Lives Matter, so do Black Technologies 
This paper’s roots lie in a re sponse to the “Black Lives 
Matter” movement, but the six examples we have 
provided thus far show how mainstream technologies are less usable for a range of underrepresented minorities. Automatic faucets and the Apple iWatch’s sensors were not properly calibrated for minority users.  The viral discussion that ensued regarding image detection to classify photographs and checking for blinking eyes both show ho w algorithms can be biased 
through design decisions or a lack of a diversity in the calibrating dataset. Finally, minority emojis and video games show how poor design decisions can perpetuate racism.  We contend that technologies can have race, and as such we as HCI pr actitioners to go beyond 
Universal Design and explicitly question the role of race  
Race Female Male 
Total  1.6mil 4mil 
Hispanic 
or Latino  114,000 227,000 
Asian 286,000 680,000 
American  
Indian or  
Alaskan 
Native  3,000 7,000 
 
 
Black or 
African 
American  108,000 159,000 
Native 
Hawaiian  
or Pacific  
Islander 2,000 9,000 
White 1.1mil 2.86mil 
Table 1. Employed Scientists & 
Engineers by Race & Gender. 
Abridged version from [26]. 
 
 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
479in our technological creations and in our corporate 
organizations.  
Representation in IT 
As demonstrated in Table 1 many minorities are severely underrepresented. Hiring more individuals of color would allow design teams opportunity to check bias and privilege [26]. However, a critical mass of individuals would need to be established in an organization to avoid putting  developers and designers 
in the position of acting as the sole spokesperson for 
their entire demographic.   
User Research 
While training and hiring a more diverse population is a long term goal, steps for en gaging in more diverse user 
research can be more immediate. Barkhuus and Rode previously published statistics showing women were grossly underrepresented in user research [4] and in that data set the race of participants was almost never discussed. We need to ensure minorities are represented adequately in ou r user testing population. 
Companies often base user research profiles on marketing data which privilege higher socio-economic status users over those for whom purchasing a given technology may be a stretch. This means there is a tension between the political agenda of racial equity and market forces. Yet, the ACM code of ethics states we must “Be fair and take action not to discriminate” [1], so as HCI professionals we must advocate for racially balanced study participants. 
Further, conducting such studies may themselves be 
logistically difficult. The last author while attempting to recruit a racially diverse sample of families for her ethnographic dissertation work found the nearest racially diverse community 44 miles away—several 
hours each way in rush hour traffic given a desire to do fieldwork in the evenings after work when families were home. Distance, combined with childcare issues (African Americans being statistically more likely to be have single-parent homes), and a tendency to hold multiple jobs can make recruiting individuals for lab based studies even more difficult. Finally, Caucasian fieldworkers, as obvious outsiders, often experience issues with rapport and that impacts their ability to collect good data. These issues need to be overcome, and we must as a community  develop strategies to 
collect the data needed for diversity.  
Value Sensitive Design (VSD)  
One way to establish this dialogue among all members 
of our community is to recogn ize that we ar e all defined 
by some sort of privilege, as recognized by intersectionalist feminist  arguments [16, 47, 55]. 
Privilege, whether inadvertent or intentional, creates spaces for bias to exist and thrive. bell hooks rightly observed that, “Acknowledgment of racism is significant when it leads to transformation” [16, p56]. Therefore, reflexivity is one way in which we can question our own privilege and bias in order to engage with VSD as a racially and culturally sensitive practice that recruits multiple perspectives to STEM [18, 41, 48, 49].  
Searle and Kafai have observed that, 
“Discussions around broadening participation often assume that boys and men are dominant in computing circles, effectively erasing the experiences of males from non-dominant racial and ethnic groups within a given context” [41, p31].  
As it is crucial we understand the design fictions surrounding the Straight White Male, we propose that we might expand this discussion to the intersections 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
480between gender and race, as both types of privilege and 
bias are often related to on e another. Race and culture 
are inextricably bound to social constructions of user groups within HCI; we ignore these crucial components at our peril. Sun has indicate d that “Insensitive design 
recommendations could end up strengthening the 
cultural essentialism designers want to leave behind in this increasingly globalized wo rld” [48; p61]. In order to 
clarify the enormous impact of how intersectionalist 
approaches to design inform the future of HCI, Sun and 
Hart-Davidson [49] caution against even inadvertent 
biases, which can emerge during the design process. They ask, “How might design features that aim to improve efficiency and effectiveness end up hurting a user’s feelings and morale, distancing him from his own community, isolating her from other users, and/or labeling him as “other”?” [49]. As Sun and Hart-Davidson inquire about how to critically understand these conceptual categories, located within the context of culturally responsive design through a discursive lens, we argue that design practices cannot be separated from the dialogic standards that inform the design fictions of how we perceive race, gender, and privilege within HCI. Reflexivity is a critical tool for HCI researchers who wish to consider race, gender, and privilege. It allows for an intersectionalist appr oaches to design (VSD, and 
racially sensitive), because it requires us to explore both our own privilege as scholars, as well as the 
biases of the communities we study [33]. We call for 
additional reflexive research trying to illuminate these issues. 
Conclusion 
This paper began when a few brave undergraduate students of color (including the first author) having read Winner [57] and motivated by the Black Lives Matter movement chose to try to explain their everyday experiences of technology in a final term paper. Professionals in the STEM fields discuss how minority students are socially isolated, but there has been little discussion to date as to how the technologies themselves are just less usable for all underrepresented minorities. The members of the Rainbow Lab, recognizing the significance of the contribution, wanted to work with this undergraduate to make sure this work was shared with the HCI community. 
The initial paper showed a passionate sense of 
vulnerability, incredulity, as well as, righteous and justified indignation. As th e more senior Rainbow Lab 
members worked to make this paper more in keeping 
with dispassionate academic traditions, we struggle with authentically representing this tone. So here as we close we again want to draw attention to the personal effect this isolation has on the lives of young underrepresented minorities. We, the technology community, are othering (making people feel excluded by not being part of a dominant social group based on race, gender etc.) many young underrepresented minorities
2, sending a not-so-
subtle signal that technology is not for them - it is for “Whites Only” [27]. This is a heartbreaking predicament. 
We hope this paper and its case studies raise awareness, and that we have begun a discussion of best design practices that are racially inclusive. We believe whole-heartedly that the HCI community deeply feels a need for inclusive design, and that we will rise and meet this challenge.  
                                                 
2 Of course, this experience of exclusion may not be felt by all 
underrepresented minorities, and we do not wish to claim 
these opinions represent the views of our colleagues that are themselves from underrepresented minorities. 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
481Acknowledgements 
We would like to thank the members of Drexel’s Fall 
2015 INFO215 class for thei r feedback on the early 
stages of this paper, all members of the Rainbow Lab especially Alexis Schleeter and Akshay Sharma for thought provoking conversation on race and IT, Dr. Michelle Rogers, and all the ALT.CHI reviewers. We would also like to thank the NSF who funded much of the preliminary research on gender on which this work was based through grant #1253465.  
References 
1. ACM. 1992. ACM Code of Ethics. (16 October 1992). 
Last retrieved January 13, 2016. https://www.acm.org/about-acm/acm-code-of-ethics-
and-professional-conduct 
2. American Standard. 2015. Installation Instructions. 
Last retrieved January 13, 2016. http://www.americanstandard-
us.com/assets/documents/amstd/install/Install_2151.
pdf  
3. Apple, 2015. Your heart ra te. What it means, and 
where on Apple Watch you’ll  find it. Last retrieved 
January, 13, 2016. https://support.apple.com/en-us/HT204666 
4. Louise Barkhuus and Jennifer A. Rode. 2007. From 
Mice to Men - 24 Years of Evaluation in CHI. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '07). ACM, New 
York, NY, USA. 
DOI=http://dx.doi.org/10.1145/1240624.2180963  
5. A.J. Berg, and Merete Lie Feminism and 
Constructivism: Do Artifacts Have Gender? Science, 
Technology and Human Values , 20, 3 1995), 332-351. 
6. Irus Braverman. 2010. Governing with Clean 
Hands:Automated Public Toilets and Sanitary Surveillance. Surveillance & Society , Vol. 8, No. 1, pp. 
1-27, 2010; Buffalo Legal Studies Research Paper No. Paper No. 2011-001. Available at SSRN: 
http://ssrn.com/abstract=1680477  
7. C.C. Cain., & E.M Trauth. (2013, May). Stereotype 
threat: the case of black males in the IT profession. In Proceedings of the 2013 annual conference on 
Computers and people research (pp. 57-62). ACM. 
8. K. Dill, D. Gentile, W.Ri chter and J. Dill. (2005) 
‘Violence, Sex, Race and Ag e in Popular Videogames’, 
in E. Cole and J. Daniel  (eds) Featuring Females: 
Feminist Analysis 
9. Tom Etter. 1985. The quantum and the homunculus 
(session QA1 addition). In Proceedings addendum of 
the 1985 ACM annual conference on The range of computing : mid-80s perspective: mid-80s perspective (ACM '85). ACM, New York, NY, USA, 4-7. 
DOI=http://dx.doi.org/10.1145/324409.324411 
10. Batya Friedman & Helen Nissenbaum. 1997. Bias in 
Computer Systems. In Human Values and the Design of Computer Technology. Friedman, eds. Cambridge 
UP: Stanford, CA p21-40 
11. K. Fuller,  L. Kvasny, E.M.Tr auth, & K.D. Joshi, (2015, 
June). Understanding Career Choice of African American Men Majoring in Information Technology. In Proceedings of the 2015 AC M SIGMIS Conference on 
Computers and People Rese arch (pp. 41-48). ACM. 
12. Feliks Garcia. 2015. 8 Times Technology Proved to Be Racist; Modern Tech has a history of privileging whiteness. NTR SCTN. Last retrieved January 13, 
2016. http://ntrsctn.com/science-tech/2015/11/racist-technology/ 
13. Lindsay D. Grace, 2012. Critical gameplay: designing 
games to critique convention. In Proceedings of the 
20th ACM international conference on Multimedia (MM '12). ACM, New York, NY, USA, 1185-1188. DOI=http://dx.doi.org/10.1145/2393347.2396414Ronald E. Anderson. 1992. Social impacts of computing: 
Codes of professional ethics. Soc Sci Comput Rev  10, 
2: 453-469.  
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
48214. Edel Greevy and Alan F. Smeaton. 2004. Classifying 
racist texts using a support vector machine. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '04). ACM, New York, NY, 
USA, 468-469. 
DOI=http://dx.doi.org/10.1145/1008992.1009074 
15. M. Griffiths.  (1999). Violent video games and 
aggression: A review of the literature. Aggression and violent behavior, 4(2), 203-212. 
16. Chad Hunter. 2012. The 15 Most Stereotypical 
Characters In Video Ga mes. Retrieved from 
http://www.complex.com/pop-culture/2012/05/the-
15-most-stereotypical-characters-in-video-games/ 
17. bell hooks. (1984) Feminist  Theory: From margin to 
center. Boston: South End Press. 
18. Yasmin Kafai, Kristin Sear le, Crîstobal Martinez, and 
Bryan Brayboy. 2014. Ethnoc omputing with electronic 
textiles: culturally responsi ve open design to broaden 
participation in computing in American Indian youth 
and communities. In Proceedings of the 45th ACM technical symposium on Computer science education (SIGCSE '14). ACM, New York, NY, USA, 241-246. 
DOI=http://dx.doi.org/10.1145/2538862.2538903  
19. Joshua Krisch. (2015) Last  retrieved January 13, 
2016. http://thegrio.com/2015/05/01/apple-watch-dark-skin/  
20. Vanessa Kitzie and Debanjan Ghosh. 2015. #Criming 
and #alive: network and content analysis of two sides 
of a story on Twitter. In Proceedings of the 78th 
ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community (ASIST '15). American Society for Information Science, Silver 
Springs, MD, USA, , Article 41 , 10 pages. 
21. Nicholas LaLone. 2014. Values levers and the 
unintended consequences of design. In Proceedings of 
the companion publication of the 17th ACM conference 
on Computer supported cooperative work & social computing (CSCW Companion '14). ACM, New York, NY, USA, 189-192. 
DOI=http://dx.doi.org/10.1145/2556420.25565 
22. Wendy Lee. How tech’s lack of diversity leads to racist 
software. SF Gate . July 22, 2015. Last retrieved 
January 13, 2016. http://www.sfgate.com/bu siness/article/How-tech-s-
lack-of-diversity-leads-to-racist-6398224.php  
23. D. Leonard (2003). Live in your world, play in ours: 
Race, video games, and consuming the other. Studies 
in Media & Information Literacy Education ,3(4), 1-9. 
24. S.-K. Lo. (2008). The nonverbal communication 
functions of emoticons in computer-mediated 
communication. CyberPsychology & Behavior , 11(5), 
595-597. 
25. B. Sri Nandhini and J. I. Sheeba.2015. Cyberbullying Detection and Classification Using Information Retrieval Algorithm. In Proceedings of the 2015 
International Conference on Advanced Research in Computer Science Engineering & Technology 
(ICARCSET 2015)  (ICARCSET '15). ACM, New York, 
NY, USA, Article 20, 5 pages. 
DOI=http://dx.doi.org/10.1145/2743065.2743085 
26. National Science Foundation. 2015. Women, Minorities 
and Persons with Disabilities in Science and Engineering, Data Table. Last retrieved 13 January, 
2016. www.nsf.gov/statistics/wmpd/ 
27. Teej Meister. 2015. Whites Only? Video. (September 
2, 2015). Last retrieved January 13, 2016. https://www.youtube.com/watch?v=WHynGQ9Vg30  
28.  H. S. Mirza, (ed) (1998). Black British feminism: A reader. London: Routledge. 
29. Kara O’Neil, 2015. 'Racist' tap will only give out soap 
to people with white skin thanks to 'discriminative' 
sensor. Mirror.  (3 September 2015). Last retrieved 
January 13, 2016. http://www.mirror.co.uk/news/weird-news/racist-tap-
only-give-out-6375873  
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
48330. Anupum Pant. 2015. Racist Sinks.  AweSci-Science 
Everyday. (6 September 2015). Last retrieved January 
13, 2016. http://awesci.com/racist-sinks/  
31. Max Plenke. 2015. The Reason This "Racist Soap 
Dispenser" Doesn't Work on Black Skin. (September 9, 2015). Last retrieved January 13, 2016. http://mic.com/articles/ 124899/the-reason-this-
racist-soap-dispenser- doesn-t-work-on-black-
skin#.IGwMF5QGS  
32. Jennifer A. Rode. 2011. A theoretical agenda for feminist HCI. Interact. Comput. 23, 5 (September 2011), 393-400. 
DOI=http://dx.doi.org/10.1016/j.intcom.2011.04.005  
33. Jennifer A. Rode. 2011. Reflexivity in digital 
anthropology. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, New York, NY, USA, 123-132. DOI=http://dx.doi.org/10.1145/1978942.1978961  
34. Adam Rose. 2010. Are face-detection cameras racist 
Retrieved from 
http://content.time.com/ti me/business/article/0,8599,
1954643,00.html 
35. Alyssa, Rosenberg. Five th ings Stephen Colbert got 
right in his response to #CancelColbert Washington 
Post. (April 1 2014). Last retrieved 13 January 12, 2016. https://www.washingtonpost.com/news/act-four/wp/2014/04/01/five-th ings-stephen-colbert-got-
right-in-his-response-to-cancelcolbert/ 
36. L. Roth. 2009. Looking at Shirley, the ultimate norm: 
Colour balance, image technologies, and cognitive 
equity. Canadian Journal of Communication , 34(1). 
37. J.F. Sargent. 2012. 5 Prejudices That Video Games 
Can't Seem to Get Over. Retrieved from http://www.cracked.com/article_19922_5-prejudices-
that-video-games-cant- seem-to-get-over.html 
38. John Scalzi Straight White Male: The Lowest Difficulty 
Setting There Is. Kotaku .(May 17, 2012). Last 
retrieved January 13, 2016. http://kotaku.com/5910857/s traight-white-male-the-
lowest-difficulty-setting-there-is 
39. Nick Schulz. 2006. The Crapiest Invetion of All Times; Why the auto-flushing toilet must die. Slate.  (March 
13, 2006). Last retrieved January 13, 2016. http://www.slate.com/artic les/arts/gizmos/2006/03/t
he_crappiest_invention_of_all_time.single.html  
40. Danny Schwartz. Ty Dolla $ign Debates Black Emojis On The Nightly Show. Hnhh: Hot New Hip Hop. 
(November 19, 2015). Last  retrieved January 13, 
2016. http://www.hotnewhiphop.com/ty-dolla-sign-debates-black-emojis-on-the-nightly-show-new-
video.36008.html 
41.  Kristin A. Searle and Yasm in B. Kafai. 2015. Boys' 
Needlework: Understanding Gendered and Indigenous 
Perspectives on Computing and Crafting with Electronic Textiles. In Proceedings of the eleventh 
annual International Conference on International 
Computing Education Research (ICER '15). ACM, New York, NY, USA, 31-39. 
DOI=http://dx.doi.org/10.1145/2787622.2787724 
42. Sloan. 2015a. Sloan BAYSY Series Faucet EFX-2XX-
X0X-0XXX. Last retrieve d January 13, 2016. 
http://www.sloanvalve.com/Specifications/EFX-
2_Series_Faucets.pdf  
43. Sloan. 2015b. Sloan BAYSY Series Faucet Active IR 
FAQs. Last ret
rieved 13 January 12, 2016. 
http://www.sloanvalve.com/Maintenance_Guides/IR_F
AQs.pdf  
44. Sloan. 2015c. Sloan BAYSY Series Faucet Brochure. 
Last retrieved January 13, 2016. http://www.sloanvalve.com/Brochures/BASYS_Brochu
re1.pdf 
45. Sandhya Somashekar and Steven Rich. Final tally: 
Police shot and killed 986 people in 2015. Washington Post. (6 January, 2016).Last retrieved 13 January 12, 
2016. 
https://www.washingtonpost.com/national/final-tally-police-shot-and-killed-984-people-in-
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
4842015/2016/01/05/3ec7a404-b3c5-11e5-a76a-
0b5145e8679a_story.html 
46. Emily Sydnor, R. M., Gregory Bova, Anatoly Gimburg, 
Sara E. Cosgrove, Trish M. Perl and Lisa L. Maragakis. (March 2012). Electronic-Eye Faucets: Legionella Species Contamination in Healthcare Settings. Infection Control & Hospital Epidemiology  / Volume 33 
/ Issue 03 / pp 235-240 
47. Gayatri Chakravorty Spivak. "Can the Subaltern 
Speak?" Marxism and the Interpretation of Culture. 
Ed. Cary Nelson and Lawrence Grossberg. Urbana: U 
of Illinois P, 1988. 271-313. 
48. H. Sun. 2015. Operationalizing culture with design 
cards: Translating critical knowledge into provocative insights. Rhetoric, Professional Communication, and 
Globalization, 7(1), 61-78. 
49. H. Sun, & W.F. Hart-Davidson. (2014, April). Binding 
the material and the discursive with a relational approach of affordances. In Proceedings of the 32nd 
annual ACM conference on Human factors in 
computing systems (pp. 3533-3542). ACM. 
50. Dan Taylor. 2015. Whoops: Apple Watch may not 
work for black people. (April 30, 2015). Last retrieved 13 January 12, 2016. http://natmonitor.com/2015/04/30/whoops-apple-
watch-may-not-work-for-black-people/  
51. JC Torpey. 2015. Apple Confirms Apple Watch 
Problems with Tatoos. Inquisitor.  (May 6 2015). Last 
retrieved January 13, 2016. 
http://www.inquisitr.com/2070216/apple-confirms-
apple-watch-problems-with-tattoos-dark-solid-ink-
blocks-heart-rate-sensors/  
52. E. M.Trauth,  C. C. Cain,  K. D. Joshi, L. Kvasny, &  K. 
Booth (2012, May). Embracing intersectionality in gender and IT career choice  research. In Proceedings 
of the 50th annual conference on Computers and People Research (pp. 199-212). ACM. 53. E. M. Trauth,  C.C. Cain , K. D. Joshi,, Kvasny, L. Kvasny, &, K. Booth (2012,  February). Understanding 
underrepresentation in IT through intersectionality. In Proceedings of the 2012 iConference (pp. 56-62). 
ACM. 
54. Paige Tutt. 2015. Apple’s new diverse emoji are even 
more problematic than before. Washington Post. April 
10, 2015. Last retrieved Ja nuary 13, 2016. Retrieved 
from 
http://www.washingtonpost. com/posteverything/wp/2
015/04/10/how-apples-new-multicultural-emojis-are-
more-racist-than-before/  
55. A. Walker. 1984. In search of our mothers' gardens: 
Womanist prose. San Diego: Harcourt Brace 
Jovanovich. 
56.  D.Williams, N. Martins, M. Consalvo, &  J. D. Ivory 
(2009). The virtual cens us: Representations of 
gender, race and age in video games. New Media & 
Society, 11(5), 815-834. 
57. Langdon Winner. 1999. Do artifacts have politics? In 
The Social Shaping of Technology  (2nd. ed.), Donald 
MacKenzie and Judy Wajcman (Eds.). Open University 
Press, Buckingham, UK, 28-40.  
58. Wanda Zamen. 2009. HP computers are racist. 
[Video file]. Retrieved 
from https://www.youtube.com/watch?v=t4DT3tQqgRM  
59. Young, I.M., 2005. On Female Body Experience: 
Throwing Like a Girl and Other Essays. Oxford UP, 
Oxford, UK.  
60. Sasheer Zamata. 2014. Weekend Update. Saturday 
Night Live. (Season 40, 2014). Retrieved from 
http://www.nbc.com/saturday-night-
live/video/weekend-update -sasheer-zamata/2834507 
 
 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
485I am really happy that these top ics are being 
broached at CHI. The primary contributions of the 
paper are (1) to bring race to our attention as an 
important factor in interaction design (2) to highlight 
and bring together for discussion specific interactio n 
problems that arise because of the tendency of 
interaction design to try to be ‘race-blind’  and in so 
doing accidentally (but structurally) become ‘blind to 
their effects on people of non -white race. ’ These 
examples are well -chosen, clearly  explained, an d 
heart -breaking.  I appreciated the discussion at the 
end about the p assion and emotions that underlie  the 
paper - this was well -done and well -placed.  
These suggestions were made to improve the paper and, as commentary, may be useful in guiding further 
work in the area.  
1) Include social theory in literature review/  
background. The authors mention, I believe correctly, that there are few sources in HCI to draw from. It is clear, however, that the authors are drawing on specific social/critical theories of r ace and marginality 
which are largely unknown in the HCI community (e.g., feminist intersectional theory; I know what this 
is but I am guessing most of the potential readers 
would not). It would be helpful to give a brief overview near the beginning of the  theories being 
drawn on to make the argument, with pointers to the literature for those interested in knowing more.  
2) Narrow the frame for what is discussed. While the 
topic of the paper from the introduction is about race 
in HCI, the actual empirical ex amples used are 
specifically about interface design issues that arise from having failed to take dark skin into account. This is a narrower set of issues than the broader questions about race in HCI, which might include, for example, examining why there so  few underrepresented 
minorities  acting as HCI practitioners, and issues that 
come up for underrepresented minority  communities 
which are marginalized in HCI for reasons other than  
skin color. For example, Andrea Grimes Parker has 
done work highlighting how the collectivist orientation  
of minority communities tends to fit poorly with the model of individual  improvement underlying  
persuasive health .  
Note that  it is not a problem for the paper that the 
exam ples are so narrowly focused,  because it would 
not be possible to do justice to the entire question in 
11 pages  anyway. It’ s also not a problem that those 
examples are placed within the context of the broader question. But the paper would benefit from  
starting with the big question in the introduction  and 
then saying, “We’ll look at this from a more specific 
lens,” bringing up the empirical examples, analyzing 
them specifically with regard to the issues relevant here, then moving out at the end to say “This is a 
beginning, it only scratches the surface of issues 
around technology an d race. ” 
3) More analysis of the empirical examples. I think it would be helpful after describing the examples to go back and show the range of  blindnesses they 
revealed, such as : (1) Lack of diversity in user 
studies (as ment ioned)  and (2) Lack of structural 
motivation in the industry to address issues even 
after they surf ace.  
 Commentary  
 
For alt.chi paper  
Does Technology Have Race?  
 
Phoebe Sengers  
Information Science and Science & 
Technology Studies  
Cornell University  
sengers@ cs.cornell.edu 
 
 
 
alt.chi: Confronting Power in HCI
#chi4good, CHI 2016, San Jose, CA, USA
486