Evaluating Student Participation in Undergraduate Information
Technology Programs in the U.S.
Mihaela Sabin
University of New Hampshire
Manchester, New Hampshire
USA
mihaela.sabin@unh.eduStuart Zweben
Ohio State University
Columbus, Ohio
USA
zweben.1@osu.edu
Barry Lunt
Brigham Young University
Provo, Utah
USA
luntb@byu.eduRajendra K. Raj
Rochester Institute of Technology
Rochester, New York
USA
rkr@cs.rit.edu
ABSTRACT
Enrollment, retention, and graduation rates of undergraduate stu-
dents in Information Technology (IT) programs are useful measures
of institutional performance. Disaggregated by demographics char-
acteristics, such as gender, race, and ethnicity, analysis of student
data across IT programs in the U.S. supports the exploration of
the breadth and diversity of student participation in IT. Evaluating
undergraduate IT programs is particularly challenging for multiple
factors, including: IT programs are not always titled "Information
Technology"; IT programs are not always ABET-accredited; and IT
programs may be housed in various academic units, such as busi-
ness, computing, engineering, technology, or information sciences.
This paper builds on prior work used to identify IT programs
in the U.S., including the National Center for Education Statistics’
Classification of Instructional Programs (CIP) codes, specifically CIP
code 11 that designates IT and other computing programs. It also
refines CIP code-based program identification and then analyzes
2017-2018 student data from the National Student Clearinghouse
Research Center to evaluate IT programs through a student partici-
pation lens. The in-depth analysis of student enrollment, retention,
and graduation is intended to support IT programs with designing
more inclusive learning environments that increase participation
of all students, in particular women and racial and ethnic minority
students. This paper finally signals the importance of CIP codes
that designate IT programs and focuses attention to the role that
faculty, IT programs, and SIGITE community at large need to have
in CIP code selection to further advance research in IT education.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGITE ’20, October 7–9, 2020, Virtual Event, USA
©2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7045-5/20/10. . . $15.00
https://doi.org/10.1145/3368308.3415396CCS CONCEPTS
•Social and professional topics →Information technology
education; Computing education programs.
KEYWORDS
information technology; enrollment; graduation; retention; CIP
codes; IPEDS
ACM Reference Format:
Mihaela Sabin, Stuart Zweben, Barry Lunt, and Rajendra K. Raj. 2020. Eval-
uating Student Participation in Undergraduate Information Technology
Programs in the U.S.. In The 21st Annual Conference on Information Tech-
nology Education (SIGITE ’20), October 7–9, 2020, Virtual Event, USA. ACM,
New York, NY, USA, 7 pages. https://doi.org/10.1145/3368308.3415396
1 INTRODUCTION
Since its inception nearly two decades ago, the SIGITE community
has successfully helped establish the Information Technology (IT)
discipline, articulate the ACM/IEEE Computer Society curriculum
recommendations for undergraduate IT programs worldwide [ 5,15],
and maintain relevant ABET CAC/CSAB IT program accreditation
criteria [ 4,9,16]. In support of its mission, SIGITE members have
constantly focused on understanding which academic computing
programs are IT [ 3,6,8], who teaches in these programs [ 7], and
how to assess the alignment of IT curricula [ 17] with the ACM/IEEE
Computer Society recommendations.
Studies [ 3,6] that evaluated the curricula of undergraduate IT
programs in the U.S. focused on both (1) identifying the colleges
and universities with IT programs, and (2) evaluating program
requirements according to the ACM/IEEE Computer Society curric-
ular recommendations [ 5,15] to determine if a program was "truly
an IT program." This paper complements these studies by examin-
ing who participates in undergraduate IT education, particularly
how many students enroll in these programs, which groups they
represent based on gender, race, and ethnicity, and what the reten-
tion and graduation rates are as measures of programs’ academic
performance.
Identifying undergraduate IT programs has been a persistent
challenge due to the widespread variation in how IT programs are
named. The disparities in nomenclature used by different computing
Session 2B: Broadening Participation in Computing 2
 
SIGITE ’20, October 7–9, 2020, Virtual Event, USA
93SIGITE ’20, October 7–9, 2020, Virtual Event, USA Sabin, Zweben, Lunt, and Raj
education communities to name computing degree programs are
a global phenomenon. A 2015 international survey of around 600
computing faculty members was conducted to study representative
names of their undergraduate computing degree programs [ 18].
The survey identified 833 programs having 234 distinct names, and
found that only six names were used ten or more times and did not
contain a shorter name that was used ten or more times. These six
names accounted for more than half of the 833 program names and,
with the exception of informatics, the remaining five were exact
matches of the then ACM-defined computing disciplines: computer
science (CS), information technology (IT), information systems (IS),
computer engineering (CE), and software engineering (SE), with
CS and IT dominating the entire name space (69%). Although it is
encouraging that the Information Technology name has significant
worldwide recognition, the long tail of name variations remains
challenging for establishing a distinct IT discipline.
Lunt et al. [ 6] proposed a methodology to identify IT programs by
using the National Center for Education Statistics (NCES) data and
the NCES College Navigator tool [ 12] to look up institutions based
on the tool search criteria, which included: (1) Information Technol-
ogy, (2) Computer and Information Sciences, and (3) Computer In-
formation Systems: Security/Information Assurance. The study [ 6]
identified 862 institutions with potential IT programs, which in-
cluded 37 ABET-accredited IT programs. All 862 programs were
assessed using evaluation criteria developed by the authors [ 15] to
reflect the ACM/IEEE Computer Society IT2017 curriculum guide-
lines for undergraduate IT programs [ 15]. Each program was as-
signed a compliance factor score that measured program alignment
with IT2017. Of the 389 institutions determined to have an IT pro-
gram, only one third (129) were named Information Technology.
The most frequent word in the program names was "Information"
(71.5%), followed by "Technology" (57.6%).
An alternative approach for identifying IT programs is the Clas-
sification of Instructional Programs taxonomic coding scheme (CIP
codes) [ 11]. NCES, a unit of the U.S. Department of Education, de-
veloped these codes in 1980 and periodically revises and updates
them to map all academic programs to a shared understanding of
the curricular content of these programs. Institutions also use CIP
codes to report degrees and certificates awarded via an annual Inte-
grated Postsecondary Education Data System (IPEDS) Completions
Survey [13].
A CIP-based approach was used to report CS enrollment, gradu-
ation, and retention data from 2016-17 [ 19]. The most recent ACM
NDC Study [ 20] also began using this CIP approach to report enroll-
ment and graduation data from non-doctoral-granting departments
with programs corresponding to the six computing disciplines for
which ACM currently has curricular guidelines and ABET has ac-
creditation criteria. The data source for these two studies is the
non-profit National Student Clearinghouse Research Center (NSC),
which gets data from nearly all U.S. colleges and universities. This
data is reported at the student level, allowing tracking of a student
from one year to the next. CIP codes allow NSC to collect student
data by program of study, providing a rich and comprehensive
database for study and analysis, including student pathways across
institutions. Consequently, institutions are highly co-interested in
participating in the NSC reporting process, and NSC has 99% of
college students enrolled by their participants.A secondary objective of this paper is to raise awareness among
IT educators about the role, usefulness, and impact of CIP codes.
These codes have institutional importance regarding student data re-
porting and NCES services that help institutions with their outreach,
recruiting, and retention decision making processes and efforts. CIP
codes are also instrumental to computing education research by IT
educators. Studies on IT programs’ curricular quality are represen-
tative examples of such research contributions [ 3,6,7,17]. Despite
the importance of CIP codes, IT faculty and department chairs are
typically not involved directly in choosing or changing these codes,
which are used to report data about their programs. The discon-
nect between departments and administrative units that decide on
CIP codes selection must be reduced to improve the accuracy of
CIP-based methodologies for studying academic programs, thus
resulting in a positive nationwide impact on computing disciplines.
This paper summarizes enrollment, graduation, and retention
data obtained from the NSC for the 2017-18 academic year from
undergraduate IT programs in the U.S. This summary aggregates
programs from both doctoral-granting and non-doctoral-granting
departments. Of particular interest are the gender, race, and eth-
nicity demographics in this data. We also compare the set of insti-
tutions obtained from the curricular-based approach [ 6] and the
CIP-based approach and discuss how this might guide future efforts
to collect data about IT programs.
2 CIP CODE 11 TAXONOMY
The CIP Code 11 taxonomy, Computer and Information Sciences
and Support Services [ 10], consists of 30 six-digit codes (11.xxxx)
across 11 four-digit groups (11.xx). These groups are: Computer and
Information Sciences General (11.01); nine groups (11.02 to 11.10)
with more specialized content, such as Programming (11.02), Data
Processing (11.03), Computer Systems Networking or Telecom-
munications (11.09), or Information Technology Administration
or Management (11.10); and a CISSS Other group (11.99). Some
of the groups have only one code, such as 11.04 Information Sci-
ence/Studies, which has only the 11.0401 code, whose name is
identical with the group’s name. The group with the most codes is
11.10. It has seven codes, primarily about system administration,
management, and support. This group also includes an increasingly
popular CIP code, 11.1003 Computer and Information Systems Se-
curity.
IT educators might naturally ask where their programs fit into
this extensive coding scheme. A brief overview of the CIP 11 evolu-
tion since its official launch in 1990 sheds light on how the develop-
ment of CIP codes has responded to the evolution of the computing
disciplines and the development of the ACM curriculum recom-
mendations reports. CIP codes are revised every ten years. In 1990,
CIP 11 had only seven groups and a total of seven codes, one code
per group. In between the computing general (11.01) and comput-
ing other (11.99) groups, the other five groups were programming
(11.02), data processing (11.03), computer science (11.07), and two
groups that represent information systems (11.04 and 11.05). From
1990 to 2000, CIP 11 recorded its most significant expansion, by
adding four more groups and 14 codes.
Although IT was not recognized by its own group, unlike CS and
IS, it received the code 11.0103 within the computing general group.
Session 2B: Broadening Participation in Computing 2
 
SIGITE ’20, October 7–9, 2020, Virtual Event, USA
94Evaluating Student Participation in Undergraduate IT Programs in the U.S. SIGITE ’20, October 7–9, 2020, Virtual Event, USA
This can be compared with Artificial intelligence that received code
11.0102 in the same group. Indicative of the IT disciplinary breadth,
three of the new groups, 11.08, 11.09, and 11.10, captured the tremen-
dous advances in IT that have been described in the IT2008 report
and inspired the "pillars" metaphor of the 2008 IT model curricu-
lum [ 5]. The new IT-related groups spanned databases, incipient
web technologies at that time, and networking. Codes in these
groups map to IT2008 knowledge areas of information assurance
and security, system administration, and system integration and
architecture. Notably, in the next two decades, of the nine newly
added codes, four are IT-related: IT project management (11.1005)
added in 2010, and subsequently human centered technology design
(11.0105), computer programming specific platforms (11.0205), and
cloud computing (11.0902) that were added in 2020.
A more in-depth analysis of the CIP 11 taxonomy and devel-
opment is beyond the scope of this paper, but we point out two
interesting findings. First, we note that the IT2008 model curricu-
lum has Human Computer Interaction as one of its five pillars and
the IT2017 report has the User Experience Design as one of the
nine essential competency domains. Both reports emphasized the
importance of integrative programming, platform technologies, and
integrated systems technologies. However, codes relevant to these
areas, 11.0205 and 11.1005, were added in 2020. Second, we observe
that out of the 25 codes that CIP 11 taxonomy had in 2010, more
than half of the codes (13) were reflective of the IT disciplinary
content and competencies. The pattern repeats in 2020, when the
majority of CIP 11 codes (17 out of 30) are IT-related.
3 CIP-BASED METHODOLOGY
The ACM Education Board funded acquisition of student data from
NSC and charged a group of members of the ACM Education Advi-
sory Committee (EAC) to analyze the data and study enrollment,
graduation outcomes, and retention of undergraduate computing
students in all six computing disciplines. A CIP code was assigned
to at most one discipline, to avoid double-counting students and
thereby confounding analyses of the student demographic data.
To have the data reported by computing discipline, the group
determined which CIP codes best reflect each discipline. After con-
sultations with members of ACM and CSAB [ 2] who have been
involved in computing curriculum and accreditation activities, the
group assigned 18 CIP 11 codes to four of the six disciplines, from
the 25 codes that comprise the CIP 11 series of the CIP-2010 edition
(in effect at the time of the study).
Table 1: CIP 11 codes assigned to ACM computing disciplines
CIP11
codes IT CS IS* Cyber**
Discipline-name d
11.0103 11.0701
Discipline-r elate
d11.0201, 11.0202, 11,0301, 11.0801
11.0802, 11.0804, 11.0899, 11.0901
11.1001, 11.1002, 11.1004, 11.100511.010111.0401
11.050111.1003
*IShas
two additional codes in CIP 52.
**Cybersecurity has one additional code in CIP 43
The group also assigned two additional codes from CIP 52 (Busi-
ness) to Information Systems, one additional code from CIP 43
(Security and Protective Services) to Cybersecurity, two codes fromCIP 14 (Engineering) to Computer Engineering, and one from CIP
14 to Software Engineering. The mapping of the CIP 11 codes to
the computing disciplines is shown in Table 1.
Thirteen CIP codes were assigned to IT, which has the largest
number of CIP codes among all computing disciplines. This is no
surprise to IT educators given the breadth and integrative nature
of the IT discipline. We call this set of CIP 11 codes the IT CIP codes.
We also note that only IT and CS have a code whose name matches
exactly the name of the discipline: 11.0103 Information Technology
and11.0701 Computer Science. The difference between the two is
that 11.0701 is the only code in the 4-digit CIP 11 series 11.07, whose
title is also Computer Science. The information technology CIP code
11.0103 is one of the five codes in the 4-digit CIP 11 series 11.01,
Computer and Information Sciences General. Another code from
this series, 11.0101, whose name is identical to the name of the
series, was assigned to CS. As we show later, the association of this
code with any of the computing disciplines remains problematic.
For historical reasons, more CS programs than other programs use
this code for their IPEDS completion survey reporting.
The mapping in Table 1 informed the NSC query to produce the
IT data set. This data set comprised 308 institutions. An institution’s
data was included in the NSC IT data set if it had reported enroll-
ment and graduation data for 2017-18, and also reported enrollment
data for 2018-19, using at least one of the IT CIP codes. These con-
straints permitted the study of program retention between 2017-18
and 2018-19. Results of our analysis of student participation in IT
programs at the 308 NSC institutions are presented and discussed
in Section 4.
In Section 5, we evaluate the application of a CIP-based approach
to identify IT programs. Our evaluation considered the publicly
available list of 389 institutions whose IT programs were scored
in 2018-2019 according to a compliance factor that measured cur-
riculum alignment with the IT curricular framework in the IT2017
report [ 6,15]. We label this list ScoredIT, as it is an important com-
ponent of our methodology.
4 STUDENT PARTICIPATION: RESULTS AND
DISCUSSION
Our analysis of the NSC enrollment, graduation, and retention
student data from the 308 institutions that comprise the NSC IT
data set includes gender, race, ethnicity, and class rank considera-
tions. Statistical analyses were performed using two-tailed z-tests
to compare the proportion of students having the characteristics of
interest. Significant differences are reported at the .01 or .05 level,
as appropriate. Tests not meeting at least the .05 level are reported
as not significant.
4.1 Enrollments
The 308 institutions enrolled a total of 104,016 students in their IT
programs. Table 2 has the enrollments breakdown by race/ethnicity
and by gender. Enrollment patterns differed among racial and ethnic
groups. Racial and ethnic minority students have had historically
low participation in computing [ 14], and comprise Black or African
American, Hispanic or Latino, Native American or Alaskan Native,
and Native Hawaiian or Pacific Islander students. Note that in
Session 2B: Broadening Participation in Computing 2
 
SIGITE ’20, October 7–9, 2020, Virtual Event, USA
95SIGITE ’20, October 7–9, 2020, Virtual Event, USA Sabin, Zweben, Lunt, and Raj
Table 2, we abbreviated the names of the racial and ethnic groups
due to the column width limitation.
Table 2: Student enrollment by race/ethnicity and gender
Race/Ethnicity Men
Women Unknown Total% Race/
Ethnicity*%
Women*
Black 7,143 3,070
581 10,794 16.7 30.1
Hispanic 6,172 1,768 193 8,133 12.6 22.3
Native American 332 96 10 438 0.7 22.4
Native Hawaiian 166 64 8 238 0.4 27.8
Non-resident 753 256 87 1,096 1.7 25.4
Two/more races 1,948 713 70 2,731 4.2 26.8
Unknown 30,056 7,476 1,747 39,279 19.9
Asian 4,640 2,019 553 7,212 11.1 30.3
White 27,210 6,287 598 34,095 52.7 18.8
Racial &
Ethnic
Minorities**13,813 4,998 792 19,603 30.3 26.6
Total
78,420 21,749 3,847 104,016 21.7
*Per
centages of racial/ethnic groups and women are calculated based on enrolled
students for whom race/ethnicity and gender were known.
**Racial
& Ethnic Minorities comprise Black/African American, Hispanic/Latino,
and Native Hawaiian/Pacific Islanders, because of their historically low participation
in computing relative to their representation in the U.S population [14]
Racial and ethnic minority students represented close to one-
third (30.3%) of the enrolled students who reported their race or
ethnicity. Another distinctive, but not surprising pattern, was that
White students represented the majority (52.7%). The share of White
and Asian students combined, 63.8%, was more than double the
representation of racial and ethnic minorities. The second and the
third largest proportions were Black/African American students
(16.7%) and Hispanic/Latino students (12.6%).
Examining enrollments of students in racial and ethnic groups by
the four class ranks (freshman, sophomore, junior, and senior), we
observed that the proportion of Black/African American students
decreased steadily from 18.1% in the freshman year to 12.3% in the
senior year (Figure 1). The difference between the representation
of Black/African American students in freshman vs. sophomore
year was significant (z=5.70, p<0.01), as was the difference between
this group’s representation in sophomore vs. junior year (z=4.22,
p<0.01). No significant difference was found between junior and
senior year. It is noteworthy that Black/African American students
comprised 13.8% of all undergraduate level students enrolled in
U.S. colleges and universities in 2017-18 for whom race/ethnicity is
known [ 13]. Thus, the representation of freshman and sophomore
Black/African American students in IT during 2017-18 exceeded
the overall representation of Black/African American students in
undergraduate education, while the reverse was true for juniors
and seniors. This suggests that retention of Black/African American
students is particularly an issue in the IT discipline. We present
more evidence of this in the next section.
The only similar decreasing trend was for the racial and ethnic
minority groups combined, whose share of enrolled students in
the freshman year was 30.7% of students whose race/ethnicity was
known and 25.4% in the senior year, despite a slight 1% increase of
the proportion of enrolled Hispanic/Latino students from freshman
(11.4%) to junior (12.4%). The proportion of racial and ethnic minori-
ties decreased significantly from freshman to sophomore (z=4.28,
p<0.01) and sophomore to junior (z=2.55, p<0.05). Across all class
Figure 1: Racial and ethnic representation of enrolled stu-
dents by class ranks
ranks, White students were the majority, with a steady 54% rate
for the first three years, and higher rate of 56% in the senior year,
which was determined to be a significant increase (z=-3.39, p<0.01).
Figure 2: Women representation of enrolled students by
class rank
The proportion of women among the total enrollment was 21.7%
(Table 2), and their proportion within various racial and ethnic
groups and class rank is shown in Figure 2. Among these groups,
White students had the lowest proportion of women (in the 18.3%
and 20.2% range) in all four years. Black students had the largest
proportion of women for the first two years: 34.5% of freshmen
and 28.6% of sophomores, while Asian students had the largest
proportion for the last two years: 30.8% of juniors and 28.6% of se-
niors. The proportions of women among Black/African American,
Hispanic/Latino, and Asian students of the enrolled students who re-
ported their race/ethnicity decreased from freshman to sophomore,
while it increased among White students. Notably, the decrease was
significant for Black/African American students (z=2.51, p<0.05).
Changes in representation showed decreases for all groups from the
freshman to senior year, and significant decreases were observed
for the representation of women among Black/African American
(z=6.98, p<0.01) and Hispanic/Latino students (z=1.96, p<0.05).
Session 2B: Broadening Participation in Computing 2
 
SIGITE ’20, October 7–9, 2020, Virtual Event, USA
96Evaluating Student Participation in Undergraduate IT Programs in the U.S. SIGITE ’20, October 7–9, 2020, Virtual Event, USA
The pattern of lower representation of women from year to year
for racial and ethnic minority students across class rank showed sig-
nificant decreases for both freshman to sophomore (z=2.43, p<0.05)
and freshman to senior (z=7.47, p<0.01).
4.2 Graduation and Retention
Of the 104,016 enrolled students, 12,136 graduated in 2017-18, 22.5%
of whom were women (Table 3). Most, but not all of the 12,136
graduates came from those who were of senior class rank; many
others came from students whose class rank was unreported. Our
working definition of retained student: a student enrolled 2017-18
is considered retained if the student either graduated from the
program in 2017-18 or was still in the program in 2018-19. Using
this definition, 72,470 students were retained in 2018-19. Of the
retained students, 21.5% were women. The proportion of women
among graduates was significantly greater than that among enrolled
students (z=2.04, p<0.05) or retained students (z=2.57, p<0.05). There
was no significant difference between the proportion of women
among enrolled vs retained students.
Table 3: Enrollment, graduation and retention counts and
women representation rates
Women
Men Unknown Total % Women
Enrollment
21,749 78,420 3,847 104,016 21.7%
Graduation 2,629 9,036 471 12,136 22.5%
Overall*
Retention14,959 54,682 2,829 72,470 21.5%
*Ov
erall retention means students who were still in the program in 2018-19
across all class ranks, combined with students who graduated in 2017-18.
Representation of women among graduates, by race/ethnicity,
is shown in Figure 3. White students had the lowest representa-
tion of women (19%), while the Asian students had the highest
representation (31.9%), among graduates whose gender was known.
The second highest representation was of Black/African American
women (26.3%). These results are consistent with the senior year
enrollment patterns observed in Figure 2.
Figure 3: Women graduation rates by race/ethnicity
Representation of racial/ethnic groups among four categories
of students: enrolled students, overall retained students, retained
seniors, and graduated seniors, are shown in Table 4. White students
were the majority for all four categories. While the representationof Asian and White students increased steadily from enrollment, to
overall retention, to retained seniors, and to graduated seniors, we
observed an opposite trend of decreasing representation for both
Black/African American and Hispanic/Latino groups.
Table 4: Racial/ethnic representation of enrolled, overall re-
tained, retained senior, and graduated senior students
%
Black%
Hispanic%
Racial/Ethnic
Minorities%
Asian%
White
Enrollment 16.7
12.6 30.3 11.1 52.7
Overall retention 14.9 12.5 28.4 12.6 53.0
Retained seniors 11.6 12.0 24.6 13.5 56.0
Graduated seniors 10.8 10.6 22.1 14.9 56.8
Tests comparing, for each race/ethnicity, the proportion of en-
rolled versus the proportion of retained students showed Asian
students significantly more strongly represented among retained
students, while Black and racial and ethnic minority students were
significantly more strongly represented among enrolled students
(z=-7.63, 8.03, and 6.87 respectively, p<0.01 in each case). Tests com-
paring proportions of overall students retained versus proportions
of seniors retained showed Black and racial and ethnic minority stu-
dents more strongly represented among overall students retained
(z=2.90 and 4.94, respectively; p<0.01 in each case), and White stu-
dents more strongly represented among seniors retained (z=-5.88,
p<0.01). Tests comparing the proportion of retained seniors versus
the proportion of graduated seniors showed that Asian students
were significantly more strongly represented among graduated se-
niors, while Hispanic and racial and ethnic minority students were
significantly more strongly represented among retained seniors
(z=-2.60, 2.86 and 3.88, respectively, p<0.01 in each case).
Collectively, these trends and results suggest that racial and
ethnic minorities had lower retention rates than White and Asian
students, and that racial and ethnic minorities were taking longer
to graduate than White and Asian students.
Figure 4: Retention rates by gender and race/ethnicity
The overall senior retention rates by gender for the various
race/ethnicity groups are in Figure 4. Retention of men was higher
for all racial/ethnic groups except for Asian students. The differ-
ences were significant for Black (z=5.14, p<0.01), racial and ethnic
Session 2B: Broadening Participation in Computing 2
 
SIGITE ’20, October 7–9, 2020, Virtual Event, USA
97SIGITE ’20, October 7–9, 2020, Virtual Event, USA Sabin, Zweben, Lunt, and Raj
minority (z=6.20, p<0.01), White (z=2.33, p<0.05) and Total (z=2.69,
p<0.01) students. The differences for Asian and Hispanic students
were not significant. This figure also shows lower retention rates for
Black and racial and ethnic minority students of either gender than
their counterparts among Asian and White students, supporting
the statement made in the previous paragraph.
5 CIP-BASED APPROACH EVALUATION
To evaluate its usefulness, we decided to apply the CIP-based ap-
proach to the ScoredIT list of 389 institutions. For each institution,
we used the NCES CIP Wizard tool [ 12] to generate the list of CIP
codes that the institutions used to report student data to IPEDS.
The NSC data would be from these same CIP codes. Two ScoredIT
institutions did not participate in the NSC and were removed from
the list. Three institutions on the ScoredIT list had multiple cam-
puses, which added four institutions to the original ScoredIT list.
Thus, the list was adjusted to have 391 institutions.
Once all CIP codes were filled in for all 391 institutions, we ana-
lyzed the coverage of the IT CIP codes across all these institutions
using a simple, "greedy" procedure. At each step, we chose the
locally best solution, knowing that it does not guarantee an opti-
mal solution, but it gives us a promising approximation. First, we
looked at the coverage of the IT 11.0103 code, which we called IT
proper, and found 206 institutions. Next we counted the institutions
with any of the other 12 IT CIP codes and found 171 institutions.
Sixty-eight institutions did not use the IT proper 11.0103 code but
did use at least one of the other IT CIP codes, and 117 institutions
used neither the IT proper 11.0103 nor another IT CIP code. Table 5
summarizes all four combinations of the IT proper 11.0103 code
and other IT CIP codes found for the 391 ScoredIT institutions.
Table 5: ScoredIT institution counts for all the four combi-
nations of the IT proper 11.0103 code and the other IT codes
Institution countswith other
IT
codeswithout other
IT
codesTotal
counts
w.r.t. 11.0103
with 11.0103
code 103 103 206
without 11.0103
code 68 117 185
Total
counts
w.r.t other IT codes171 220
To maximize the coverage of the IT CIP codes using our greedy
procedure, we considered all 206 institutions with the IT proper
11.0301 code and the additional 68 institutions that had at least
another IT code, for a total of 274 institutions (70% of all ScoredIT
institutions). Another way of obtaining the same result was to
consider the 171 institutions with at least one non-proper IT code,
along with the 103 institutions that had the IT proper code but none
of the other IT codes. Next, we looked for institutions that did not
have any IT CIP code, but had both the CS proper 11.0701 code and
the CS Computing General 11.0101 code. We hypothesized that by
having two CS CIP codes, a department most likely had a CS and
an IT program. This step added 30 more institutions for a total of
304 institutions (78% of all ScoredIT), as shown in Table 6.
Another evaluative measure of the CIP-based approach to iden-
tify IT programs was to find out how many of the ScoredIT andTable 6: Potential use of CIP codes to designate IT programs
that maximize coverage of the ScoredIT institutions
IT
proper
11.0310Other IT codes
but not IT properNeither IT codes
nor CS proper 11.0701
but CS general 11.0101Total
Institution
counts206 68 30 304
NSC institutions had programs that were ABET IT accredited. Of
the 39 institutions with ABET IT accreditation in 2018-19, 95% (37)
were in the ScoredIT list and 72% (28) were in the NSC list. The
two lists had 178 institutions in common, which had 62% (24) of
the ABET IT accredited institutions.
6 CONCLUSION AND FUTURE WORK
This paper presented an in-depth analysis of IT student enrollment,
retention, and graduation data, disaggregated by gender, race, and
class rank. Such analyses offer insights into the breadth and diver-
sity of student participation in IT education. The data was generated
using a CIP code approach, and the paper provided an awareness
of CIP codes and their use in institutional reporting of important
educational information.
CIP codes also can provide insights to aid IT programs frame
educational strategies for increasing participation of all students.
For example, in a general study about trends in lifelong learning,
Brown et al. [ 1] applied a CIP/IPEDS approach to understand the
development of new and improved skills among middle- and older-
aged adults enrolled in 2- and 4-year programs. Such studies can
be adapted to IT, as they provide valuable insight into how institu-
tions can develop IT program and curricula to help address current
employment needs across the U.S. among different demographics.
The paper also illustrates that the CIP approach has limitations
due to the accuracy of assigning proper CIP codes to IT programs
within institutions. In order for the IT community to use CIP codes
to identify IT programs reliably, efforts need to be made to reduce
or eliminate use of the same code by programs from multiple disci-
plines, for example, an institution must avoid using one code for
both CS and IT. It is thus incumbent upon IT department chairs,
program coordinators and faculty yo take an active role in ensuring
proper CIP codes are assigned to their programs at their institutions.
It is important for future studies to capture the full scope of
CIP codes that reflect the IT discipline. Benchmarks such as codes
used by programs having obtained IT accreditation or otherwise
evaluated as being highly consistent with approved IT curriculum
guidelines is a good starting point for such efforts.
ACKNOWLEDGMENTS
The authors are grateful to the ACM Education Board and ACM
Committee for Computing Education in Community Colleges for
financial support, and to the ACM Education Advisory Committee
for feedback on data analysis related to this study. We also acknowl-
edge several discussions with educators and practitioners about
the IT discipline, including Sandra Gorka, Jim Leone, Scott Murray,
Edward Sobiesk, Mary Jane Willshire, and many others.
Session 2B: Broadening Participation in Computing 2
 
SIGITE ’20, October 7–9, 2020, Virtual Event, USA
98Evaluating Student Participation in Undergraduate IT Programs in the U.S. SIGITE ’20, October 7–9, 2020, Virtual Event, USA
REFERENCES
[1]J Scott Brown, Nader Mehri, Phyllis Cummins, Peter Riley Bahr, and Pallavi
Timilsina. 2017. Understanding the enrollment trends among older learners in
higher education in Ohio. Innovation in Aging 1 (6 2017), 1204–1204. https:
//doi.org/10.1093/geroni/igx004.4380.
[2]CSAB.org. 2020. CSAB Leadership. https://csab.org/about-us/#leadership,
Accessed Aug 12, 2020.
[3]Andrew Hansen, Bikalpa Neupane, Barry M. Lunt, and Richard Ofori. 2012.
Identifying and Evaluating Information Technology Bachelor’s Degree Programs.
InProceedings of the 1st Annual Conference on Research in Information Technology
(RIIT ’12). ACM, New York, 19–24. https://doi.org/10.1145/2380790.2380796.
[4]C. Richard G. Helps, Barry M. Lunt, and David K. Anthony. 2005. ABET
Accreditation with IT Criteria. In Proceedings of the 6th Conference on Infor-
mation Technology Education (SIGITE ’05). ACM, New York, 353–359. https:
//doi.org/10.1145/1095714.1095716.
[5]Barry Lunt, Joseph Ekstrom, Sandra Gorka, Greg Hislop, Reza Kamali, Eydie
Lawson, Richard LeBlanc, Jacob Miller, and Han Reichgelt. 2008. Curriculum
Guidelines for Undergraduate Degree Programs in Information Technology. Techni-
cal Report. ACM/IEEE Computer Society Task Force, New York.
[6]Barry Lunt, Brady Redfearn, Elizabeth Mitchell, Samuel Tenney, and Cayman
Williams. 2019. Identifying and Evaluating Information Technology Baccalaureate
Degree Programs per IT2017. In Proceedings of the 20th Annual SIG Conference
on Information Technology Education (SIGITE ’19). ACM, New York, 5–9. https:
//doi.org/10.1145/3349266.3351413.
[7]Barry M. Lunt and Michael Q. Adams. 2013. Identifying Information Technology
Graduate-Level Programs. In Proceedings of the 14th Annual ACM SIGITE Confer-
ence on Information Technology Education (SIGITE ’13). ACM, New York, 55–58.
https://doi.org/10.1145/2512276.2512280.
[8]Barry M. Lunt and Bill Paterson. 2014. An Academic Profile of IT Faculty in
the USA. In Proceedings of the 15th Annual Conference on Information Technology
Education (SIGITE ’14). ACM, New York, 163–166. https://doi.org/10.1145/2656450.
2656455.
[9]Scott Murray, Sandra Gorka, Becky Rutherfoord, and Mihaela Sabin. 2018. Re-
vising the ABET Information Technology Criteria to Reflect the IT 2017 Cur-
riculum Guidelines. In Proceedings of the 19th Annual Conference on Informa-
tion Technology Education (SIGITE ’18). ACM, New York, 184–185. https://doi.org/10.1145/3241815.3241843.
[10] National Center for Educational Statistics. 2010. Detail for CIP Code 11. https:
//nces.ed.gov/ipeds/cipcode/cipdetail.aspx?y=55&cipid=88073, Accessed Aug 12,
2020.
[11] National Center for Educational Statistics. 2019. Introducing the
2020 Classification of Instructional Programs (CIP) and Its Website.
https://nces.ed.gov/blogs/nces/post/introducing-the-2020-classification-
of-instructional-programs-cip-and-its-website, Accessed Aug 12, 2020.
[12] National Center for Educational Statistics. 2020. College Navigator. https:
//nces.ed.gov/collegenavigator/, Accessed Aug 12, 2020.
[13] National Center for Educational Statistics. 2020. Integrated Postsecondary Edu-
cation Data System (IPEDS).
[14] National Center for Science National Science Foundation and Engineering
Statistics. 2019. Women, Minorities, and Persons with Disabilities in Science
and Engineering: 2019. Technical Report NSF 19-304. NSF, Alexandria, VA.
https://www.nsf.gov/statistics/wmpd, Accessed Aug 12, 2020.
[15] Task Group on Information Technology Curricula. 2017. Information Technol-
ogy Curricula 2017: Curriculum Guidelines for Baccalaureate Degree Programs in
Information Technology. ACM, New York.
[16] Rajendra K. Raj, Jim Leone, Allen Parrish, and Mihaela Sabin. 2017. Rebooting
Information Technology Programs: Panel. In Proceedings of the 18th Annual
Conference on Information Technology Education (SIGITE ’17) . ACM, New York,
133–134. https://doi.org/10.1145/3125659.3125671
[17] Dale C. Rowe, Barry M. Lunt, and Richard G. Helps. 2011. An Assessment
Framework for Identifying Information Technology Programs. In Proceedings of
the 2011 Conference on Information Technology Education (SIGITE ’11). ACM, New
York, 123–128. https://doi.org/10.1145/2047594.2047630
[18] Mihaela Sabin, Paul Snow, Simon, John Impagliazzo, Alison Clear, and Yan
Timanovsky. 2018. Representative Names of Computing Degree Programs World-
wide. In Proceedings of the 20th Australasian Computing Education Conference
(ACE ’18). ACM, New York, 105–112. https://doi.org/10.1145/3160489.3160501
[19] Stuart Zweben. 2019. Enrollment and Retention in U.S. Computer Science Bach-
elor’s Programs in 2016-17. ACM Inroads 10, 4 (Nov. 2019), 47–59. https:
//doi.org/10.1145/3366690
[20] Stuart Zweben, Jodi Tims, and Yan Timanovsky. 2020. ACM-NDC Study 2018–
2019: Eighth Annual Study of Non-Doctoral-Granting Departments in Computing.
ACM Inroads 11, 3 (2020), To appear in September 2020.
Session 2B: Broadening Participation in Computing 2
 
SIGITE ’20, October 7–9, 2020, Virtual Event, USA
99